[2025-01-03 20:45:33,372] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to npu (auto detect)
[2025-01-03 20:45:33,634] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to npu (auto detect)
[2025-01-03 20:45:33,729] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to npu (auto detect)
[2025-01-03 20:45:33,734] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to npu (auto detect)
[2025-01-03 20:45:33,740] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to npu (auto detect)
[2025-01-03 20:45:33,743] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to npu (auto detect)
[2025-01-03 20:45:33,752] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to npu (auto detect)
[2025-01-03 20:45:33,778] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to npu (auto detect)
[2025-01-03 20:45:33,850] [WARNING] [comm.py:163:init_deepspeed_backend] HCCL backend in DeepSpeed not yet implemented
[2025-01-03 20:45:33,850] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-01-03 20:45:34,121] [WARNING] [comm.py:163:init_deepspeed_backend] HCCL backend in DeepSpeed not yet implemented
[2025-01-03 20:45:34,121] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-01-03 20:45:34,122] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend hccl
[2025-01-03 20:45:34,213] [WARNING] [comm.py:163:init_deepspeed_backend] HCCL backend in DeepSpeed not yet implemented
[2025-01-03 20:45:34,213] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-01-03 20:45:34,215] [WARNING] [comm.py:163:init_deepspeed_backend] HCCL backend in DeepSpeed not yet implemented
[2025-01-03 20:45:34,215] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-01-03 20:45:34,222] [WARNING] [comm.py:163:init_deepspeed_backend] HCCL backend in DeepSpeed not yet implemented
[2025-01-03 20:45:34,222] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-01-03 20:45:34,224] [WARNING] [comm.py:163:init_deepspeed_backend] HCCL backend in DeepSpeed not yet implemented
[2025-01-03 20:45:34,225] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-01-03 20:45:34,228] [WARNING] [comm.py:163:init_deepspeed_backend] HCCL backend in DeepSpeed not yet implemented
[2025-01-03 20:45:34,228] [INFO] [comm.py:637:init_distributed] cdb=None
[2025-01-03 20:45:34,264] [WARNING] [comm.py:163:init_deepspeed_backend] HCCL backend in DeepSpeed not yet implemented
[2025-01-03 20:45:34,264] [INFO] [comm.py:637:init_distributed] cdb=None
[W compiler_depend.ts:623] Warning: expandable_segments currently defaults to false. You can enable this feature by `export PYTORCH_NPU_ALLOC_CONF = expandable_segments:True`. (function operator())
[W compiler_depend.ts:623] Warning: expandable_segments currently defaults to false. You can enable this feature by `export PYTORCH_NPU_ALLOC_CONF = expandable_segments:True`. (function operator())
[W compiler_depend.ts:623] Warning: expandable_segments currently defaults to false. You can enable this feature by `export PYTORCH_NPU_ALLOC_CONF = expandable_segments:True`. (function operator())
[W compiler_depend.ts:623] Warning: expandable_segments currently defaults to false. You can enable this feature by `export PYTORCH_NPU_ALLOC_CONF = expandable_segments:True`. (function operator())
[W compiler_depend.ts:623] Warning: expandable_segments currently defaults to false. You can enable this feature by `export PYTORCH_NPU_ALLOC_CONF = expandable_segments:True`. (function operator())
[W compiler_depend.ts:623] Warning: expandable_segments currently defaults to false. You can enable this feature by `export PYTORCH_NPU_ALLOC_CONF = expandable_segments:True`. (function operator())
[W compiler_depend.ts:623] Warning: expandable_segments currently defaults to false. You can enable this feature by `export PYTORCH_NPU_ALLOC_CONF = expandable_segments:True`. (function operator())
[W compiler_depend.ts:623] Warning: expandable_segments currently defaults to false. You can enable this feature by `export PYTORCH_NPU_ALLOC_CONF = expandable_segments:True`. (function operator())

Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
Loading checkpoint shards:  25%|██▌       | 1/4 [00:02<00:06,  2.01s/it]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
Loading checkpoint shards:  25%|██▌       | 1/4 [00:02<00:06,  2.06s/it]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
Loading checkpoint shards:  25%|██▌       | 1/4 [00:02<00:06,  2.13s/it]
Loading checkpoint shards:  25%|██▌       | 1/4 [00:02<00:08,  2.97s/it]
Loading checkpoint shards:  25%|██▌       | 1/4 [00:01<00:05,  1.78s/it]
Loading checkpoint shards:  50%|█████     | 2/4 [00:03<00:03,  1.71s/it]
Loading checkpoint shards:  50%|█████     | 2/4 [00:03<00:03,  1.68s/it]
Loading checkpoint shards:  25%|██▌       | 1/4 [00:01<00:04,  1.65s/it]
Loading checkpoint shards:  50%|█████     | 2/4 [00:03<00:03,  1.78s/it]
Loading checkpoint shards:  25%|██▌       | 1/4 [00:02<00:06,  2.07s/it]
Loading checkpoint shards:  50%|█████     | 2/4 [00:03<00:03,  1.51s/it]
Loading checkpoint shards:  25%|██▌       | 1/4 [00:02<00:06,  2.02s/it]
Loading checkpoint shards:  50%|█████     | 2/4 [00:04<00:04,  2.11s/it]
Loading checkpoint shards:  75%|███████▌  | 3/4 [00:04<00:01,  1.48s/it]
Loading checkpoint shards:  50%|█████     | 2/4 [00:02<00:02,  1.25s/it]
Loading checkpoint shards:  75%|███████▌  | 3/4 [00:04<00:01,  1.42s/it]
Loading checkpoint shards:  50%|█████     | 2/4 [00:02<00:02,  1.37s/it]
Loading checkpoint shards:  75%|███████▌  | 3/4 [00:04<00:01,  1.41s/it]
Loading checkpoint shards:  50%|█████     | 2/4 [00:02<00:02,  1.32s/it]
Loading checkpoint shards:  75%|███████▌  | 3/4 [00:04<00:01,  1.29s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [00:05<00:00,  1.24s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [00:05<00:00,  1.40s/it]

Loading checkpoint shards:  75%|███████▌  | 3/4 [00:05<00:01,  1.64s/it]
Loading checkpoint shards:  75%|███████▌  | 3/4 [00:03<00:01,  1.10s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [00:05<00:00,  1.24s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [00:05<00:00,  1.39s/it]
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.

Loading checkpoint shards:  75%|███████▌  | 3/4 [00:04<00:01,  1.25s/it]
Loading checkpoint shards:  75%|███████▌  | 3/4 [00:03<00:01,  1.19s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [00:05<00:00,  1.36s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [00:05<00:00,  1.48s/it]

Loading checkpoint shards: 100%|██████████| 4/4 [00:05<00:00,  1.21s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [00:05<00:00,  1.30s/it]

Loading checkpoint shards: 100%|██████████| 4/4 [00:04<00:00,  1.06s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [00:04<00:00,  1.14s/it]

Loading checkpoint shards: 100%|██████████| 4/4 [00:06<00:00,  1.43s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [00:06<00:00,  1.66s/it]
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.

Loading checkpoint shards: 100%|██████████| 4/4 [00:04<00:00,  1.09s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [00:04<00:00,  1.22s/it]

Loading checkpoint shards: 100%|██████████| 4/4 [00:04<00:00,  1.05s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [00:04<00:00,  1.18s/it]
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
/work/.env/openmind_finetune/lib/python3.10/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: 
dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)
  warnings.warn(
/work/.env/openmind_finetune/lib/python3.10/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: 
dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)
  warnings.warn(
/work/.env/openmind_finetune/lib/python3.10/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: 
dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)
  warnings.warn(
/work/.env/openmind_finetune/lib/python3.10/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: 
dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)
  warnings.warn(
/work/.env/openmind_finetune/lib/python3.10/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: 
dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)
  warnings.warn(
Detected kernel version 4.19.90, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
/work/.env/openmind_finetune/lib/python3.10/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: 
dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)
  warnings.warn(
/work/.env/openmind_finetune/lib/python3.10/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: 
dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)
  warnings.warn(
/work/.env/openmind_finetune/lib/python3.10/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: 
dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)
  warnings.warn(
Warning: The torch.npu.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='npu') to create tensors.
Warning: The torch.npu.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='npu') to create tensors.
Warning: The torch.npu.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='npu') to create tensors.
Warning: The torch.npu.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='npu') to create tensors.
Warning: The torch.npu.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='npu') to create tensors.
Warning: The torch.npu.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='npu') to create tensors.
Warning: The torch.npu.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='npu') to create tensors.
Warning: The torch.npu.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='npu') to create tensors.

  0%|          | 0/200 [00:00<?, ?it/s]Warning: Device do not support double dtype now, dtype cast repalce with float.
Warning: Device do not support double dtype now, dtype cast repalce with float.
Warning: Device do not support double dtype now, dtype cast repalce with float.
Warning: Device do not support double dtype now, dtype cast repalce with float.
Warning: Device do not support double dtype now, dtype cast repalce with float.
Warning: Device do not support double dtype now, dtype cast repalce with float.
Warning: Device do not support double dtype now, dtype cast repalce with float.
Warning: Device do not support double dtype now, dtype cast repalce with float.

  0%|          | 1/200 [00:04<15:37,  4.71s/it]
                                               
{'loss': 2.4223, 'grad_norm': 12.757014121719777, 'learning_rate': 8.333333333333333e-07, 'epoch': 0.02}

  0%|          | 1/200 [00:05<15:37,  4.71s/it]
  1%|          | 2/200 [00:06<10:10,  3.08s/it]
                                               
{'loss': 1.9904, 'grad_norm': 11.889331401381451, 'learning_rate': 1.6666666666666667e-06, 'epoch': 0.03}

  1%|          | 2/200 [00:06<10:10,  3.08s/it]
  2%|▏         | 3/200 [00:07<06:50,  2.08s/it]
                                               
{'loss': 2.5132, 'grad_norm': 15.037846947628923, 'learning_rate': 2.5e-06, 'epoch': 0.05}

  2%|▏         | 3/200 [00:07<06:50,  2.08s/it]
  2%|▏         | 4/200 [00:08<05:15,  1.61s/it]
                                               
{'loss': 2.4874, 'grad_norm': 14.103358070413751, 'learning_rate': 3.3333333333333333e-06, 'epoch': 0.06}

  2%|▏         | 4/200 [00:08<05:15,  1.61s/it]
  2%|▎         | 5/200 [00:09<04:55,  1.51s/it]
                                               
{'loss': 2.3114, 'grad_norm': 13.60818704003592, 'learning_rate': 4.166666666666667e-06, 'epoch': 0.08}

  2%|▎         | 5/200 [00:09<04:55,  1.51s/it]
  3%|▎         | 6/200 [00:10<04:21,  1.35s/it]
                                               
{'loss': 2.2989, 'grad_norm': 13.16211386727368, 'learning_rate': 5e-06, 'epoch': 0.1}

  3%|▎         | 6/200 [00:10<04:21,  1.35s/it]
  4%|▎         | 7/200 [00:11<03:51,  1.20s/it]
                                               
{'loss': 2.4329, 'grad_norm': 13.610768015855877, 'learning_rate': 4.9996722091640805e-06, 'epoch': 0.11}

  4%|▎         | 7/200 [00:11<03:51,  1.20s/it]
  4%|▍         | 8/200 [00:12<03:32,  1.11s/it]
                                               
{'loss': 2.3191, 'grad_norm': 12.097270285657745, 'learning_rate': 4.998688922613788e-06, 'epoch': 0.13}

  4%|▍         | 8/200 [00:12<03:32,  1.11s/it]
  4%|▍         | 9/200 [00:13<03:19,  1.04s/it]
                                               
{'loss': 2.9831, 'grad_norm': 15.443714944883828, 'learning_rate': 4.997050398198977e-06, 'epoch': 0.14}

  4%|▍         | 9/200 [00:13<03:19,  1.04s/it]
  5%|▌         | 10/200 [00:14<03:08,  1.01it/s]
                                                
{'loss': 2.3273, 'grad_norm': 11.67922827797048, 'learning_rate': 4.99475706559428e-06, 'epoch': 0.16}

  5%|▌         | 10/200 [00:14<03:08,  1.01it/s]
  6%|▌         | 11/200 [00:15<03:02,  1.04it/s]
                                                
{'loss': 2.3537, 'grad_norm': 12.379249536696353, 'learning_rate': 4.991809526186424e-06, 'epoch': 0.18}

  6%|▌         | 11/200 [00:15<03:02,  1.04it/s]
  6%|▌         | 12/200 [00:16<03:01,  1.03it/s]
                                                
{'loss': 2.1778, 'grad_norm': 10.49572739637904, 'learning_rate': 4.988208552916535e-06, 'epoch': 0.19}

  6%|▌         | 12/200 [00:16<03:01,  1.03it/s]
  6%|▋         | 13/200 [00:17<02:57,  1.06it/s]
                                                
{'loss': 2.3352, 'grad_norm': 13.525680417698725, 'learning_rate': 4.983955090077445e-06, 'epoch': 0.21}

  6%|▋         | 13/200 [00:17<02:57,  1.06it/s]
  7%|▋         | 14/200 [00:18<02:52,  1.08it/s]
                                                
{'loss': 2.4647, 'grad_norm': 11.948448073994928, 'learning_rate': 4.979050253066064e-06, 'epoch': 0.22}

  7%|▋         | 14/200 [00:18<02:52,  1.08it/s]
  8%|▊         | 15/200 [00:18<02:50,  1.09it/s]
                                                
{'loss': 2.3212, 'grad_norm': 12.838815748321023, 'learning_rate': 4.973495328090891e-06, 'epoch': 0.24}

  8%|▊         | 15/200 [00:18<02:50,  1.09it/s]
  8%|▊         | 16/200 [00:19<02:48,  1.09it/s]
                                                
{'loss': 2.2211, 'grad_norm': 13.18616005114951, 'learning_rate': 4.967291771834727e-06, 'epoch': 0.26}

  8%|▊         | 16/200 [00:19<02:48,  1.09it/s]
  8%|▊         | 17/200 [00:20<02:50,  1.07it/s]
                                                
{'loss': 2.1972, 'grad_norm': 10.508016523344585, 'learning_rate': 4.960441211072686e-06, 'epoch': 0.27}

  8%|▊         | 17/200 [00:20<02:50,  1.07it/s]
  9%|▉         | 18/200 [00:21<02:49,  1.07it/s]
                                                
{'loss': 2.1067, 'grad_norm': 10.710667535118974, 'learning_rate': 4.952945442245598e-06, 'epoch': 0.29}

  9%|▉         | 18/200 [00:21<02:49,  1.07it/s]
 10%|▉         | 19/200 [00:22<02:53,  1.04it/s]
                                                
{'loss': 1.8087, 'grad_norm': 9.398016586454684, 'learning_rate': 4.944806430988927e-06, 'epoch': 0.3}

 10%|▉         | 19/200 [00:22<02:53,  1.04it/s]
 10%|█         | 20/200 [00:23<02:53,  1.03it/s]
                                                
{'loss': 2.023, 'grad_norm': 10.681050457103341, 'learning_rate': 4.936026311617316e-06, 'epoch': 0.32}

 10%|█         | 20/200 [00:23<02:53,  1.03it/s]
 10%|█         | 21/200 [00:24<02:49,  1.06it/s]
                                                
{'loss': 2.2772, 'grad_norm': 11.643091050656057, 'learning_rate': 4.926607386564898e-06, 'epoch': 0.34}

 10%|█         | 21/200 [00:24<02:49,  1.06it/s]
 11%|█         | 22/200 [00:25<02:45,  1.08it/s]
                                                
{'loss': 2.1967, 'grad_norm': 11.578189576827334, 'learning_rate': 4.916552125781529e-06, 'epoch': 0.35}

 11%|█         | 22/200 [00:25<02:45,  1.08it/s]
 12%|█▏        | 23/200 [00:26<02:41,  1.09it/s]
                                                
{'loss': 1.8763, 'grad_norm': 11.301085387909616, 'learning_rate': 4.905863166085076e-06, 'epoch': 0.37}

 12%|█▏        | 23/200 [00:26<02:41,  1.09it/s]
 12%|█▏        | 24/200 [00:27<02:42,  1.08it/s]
                                                
{'loss': 2.0082, 'grad_norm': 12.490664238351552, 'learning_rate': 4.894543310469968e-06, 'epoch': 0.38}

 12%|█▏        | 24/200 [00:27<02:42,  1.08it/s]
 12%|█▎        | 25/200 [00:28<02:39,  1.09it/s]
                                                
{'loss': 1.9636, 'grad_norm': 10.530565007512246, 'learning_rate': 4.8825955273721524e-06, 'epoch': 0.4}

 12%|█▎        | 25/200 [00:28<02:39,  1.09it/s]
 13%|█▎        | 26/200 [00:29<02:37,  1.11it/s]
                                                
{'loss': 1.8379, 'grad_norm': 10.621226280089841, 'learning_rate': 4.870022949890676e-06, 'epoch': 0.42}

 13%|█▎        | 26/200 [00:29<02:37,  1.11it/s]
 14%|█▎        | 27/200 [00:30<02:34,  1.12it/s]
                                                
{'loss': 1.838, 'grad_norm': 11.994310937817431, 'learning_rate': 4.856828874966086e-06, 'epoch': 0.43}

 14%|█▎        | 27/200 [00:30<02:34,  1.12it/s]
 14%|█▍        | 28/200 [00:31<02:42,  1.06it/s]
                                                
{'loss': 1.6525, 'grad_norm': 10.128871977983863, 'learning_rate': 4.84301676251586e-06, 'epoch': 0.45}

 14%|█▍        | 28/200 [00:31<02:42,  1.06it/s]
 14%|█▍        | 29/200 [00:31<02:38,  1.08it/s]
                                                
{'loss': 1.8273, 'grad_norm': 11.528514506583909, 'learning_rate': 4.828590234527107e-06, 'epoch': 0.46}

 14%|█▍        | 29/200 [00:31<02:38,  1.08it/s]
 15%|█▌        | 30/200 [00:32<02:35,  1.09it/s]
                                                
{'loss': 1.8203, 'grad_norm': 10.762625798322036, 'learning_rate': 4.813553074106761e-06, 'epoch': 0.48}

 15%|█▌        | 30/200 [00:32<02:35,  1.09it/s]
 16%|█▌        | 31/200 [00:33<02:33,  1.10it/s]
                                                
{'loss': 1.8025, 'grad_norm': 11.142842589707705, 'learning_rate': 4.797909224489531e-06, 'epoch': 0.5}

 16%|█▌        | 31/200 [00:33<02:33,  1.10it/s]
 16%|█▌        | 32/200 [00:34<02:31,  1.11it/s]
                                                
{'loss': 1.8116, 'grad_norm': 11.569159821887457, 'learning_rate': 4.781662788003851e-06, 'epoch': 0.51}

 16%|█▌        | 32/200 [00:34<02:31,  1.11it/s]
 16%|█▋        | 33/200 [00:35<02:31,  1.10it/s]
                                                
{'loss': 1.7481, 'grad_norm': 11.086157035132471, 'learning_rate': 4.764818024996117e-06, 'epoch': 0.53}

 16%|█▋        | 33/200 [00:35<02:31,  1.10it/s]
 17%|█▋        | 34/200 [00:36<02:29,  1.11it/s]
                                                
{'loss': 1.6787, 'grad_norm': 10.524412567345282, 'learning_rate': 4.747379352713489e-06, 'epoch': 0.54}

 17%|█▋        | 34/200 [00:36<02:29,  1.11it/s]
 18%|█▊        | 35/200 [00:37<02:27,  1.12it/s]
                                                
{'loss': 1.4533, 'grad_norm': 10.066243677747185, 'learning_rate': 4.729351344145536e-06, 'epoch': 0.56}

 18%|█▊        | 35/200 [00:37<02:27,  1.12it/s]
 18%|█▊        | 36/200 [00:38<02:27,  1.11it/s]
                                                
{'loss': 1.6634, 'grad_norm': 11.287897998978886, 'learning_rate': 4.710738726825059e-06, 'epoch': 0.58}

 18%|█▊        | 36/200 [00:38<02:27,  1.11it/s]
 18%|█▊        | 37/200 [00:39<02:26,  1.11it/s]
                                                
{'loss': 1.3801, 'grad_norm': 9.46135400159285, 'learning_rate': 4.69154638158837e-06, 'epoch': 0.59}

 18%|█▊        | 37/200 [00:39<02:26,  1.11it/s]
 19%|█▉        | 38/200 [00:40<02:24,  1.12it/s]
                                                
{'loss': 1.4414, 'grad_norm': 11.170169982982822, 'learning_rate': 4.671779341295378e-06, 'epoch': 0.61}

 19%|█▉        | 38/200 [00:40<02:24,  1.12it/s]
 20%|█▉        | 39/200 [00:40<02:24,  1.12it/s]
                                                
{'loss': 1.5789, 'grad_norm': 10.937305732091707, 'learning_rate': 4.651442789509813e-06, 'epoch': 0.62}

 20%|█▉        | 39/200 [00:40<02:24,  1.12it/s]
 20%|██        | 40/200 [00:41<02:22,  1.12it/s]
                                                
{'loss': 2.0488, 'grad_norm': 16.814545574326228, 'learning_rate': 4.630542059139923e-06, 'epoch': 0.64}

 20%|██        | 40/200 [00:41<02:22,  1.12it/s]
 20%|██        | 41/200 [00:42<02:22,  1.12it/s]
                                                
{'loss': 1.5497, 'grad_norm': 11.43263749951482, 'learning_rate': 4.609082631040012e-06, 'epoch': 0.66}

 20%|██        | 41/200 [00:42<02:22,  1.12it/s]
 21%|██        | 42/200 [00:43<02:20,  1.12it/s]
                                                
{'loss': 1.2229, 'grad_norm': 10.927977858379938, 'learning_rate': 4.587070132573178e-06, 'epoch': 0.67}

 21%|██        | 42/200 [00:43<02:20,  1.12it/s]
 22%|██▏       | 43/200 [00:44<02:18,  1.13it/s]
                                                
{'loss': 1.6242, 'grad_norm': 12.356496212811566, 'learning_rate': 4.564510336135642e-06, 'epoch': 0.69}

 22%|██▏       | 43/200 [00:44<02:18,  1.13it/s]
 22%|██▏       | 44/200 [00:45<02:19,  1.12it/s]
                                                
{'loss': 1.2977, 'grad_norm': 11.292860655397575, 'learning_rate': 4.541409157643027e-06, 'epoch': 0.7}

 22%|██▏       | 44/200 [00:45<02:19,  1.12it/s]
 22%|██▎       | 45/200 [00:46<02:18,  1.12it/s]
                                                
{'loss': 1.304, 'grad_norm': 10.299875751227422, 'learning_rate': 4.517772654979024e-06, 'epoch': 0.72}

 22%|██▎       | 45/200 [00:46<02:18,  1.12it/s]
 23%|██▎       | 46/200 [00:47<02:17,  1.12it/s]
                                                
{'loss': 1.2169, 'grad_norm': 12.19349186642138, 'learning_rate': 4.493607026406802e-06, 'epoch': 0.74}

 23%|██▎       | 46/200 [00:47<02:17,  1.12it/s]
 24%|██▎       | 47/200 [00:48<02:15,  1.13it/s]
                                                
{'loss': 1.0029, 'grad_norm': 10.069756397077557, 'learning_rate': 4.4689186089436365e-06, 'epoch': 0.75}

 24%|██▎       | 47/200 [00:48<02:15,  1.13it/s]
 24%|██▍       | 48/200 [00:48<02:15,  1.12it/s]
                                                
{'loss': 1.2401, 'grad_norm': 12.621475180904469, 'learning_rate': 4.443713876699124e-06, 'epoch': 0.77}

 24%|██▍       | 48/200 [00:48<02:15,  1.12it/s]
 24%|██▍       | 49/200 [00:49<02:13,  1.13it/s]
                                                
{'loss': 1.1534, 'grad_norm': 10.86884072053678, 'learning_rate': 4.417999439177465e-06, 'epoch': 0.78}

 24%|██▍       | 49/200 [00:49<02:13,  1.13it/s]
 25%|██▌       | 50/200 [00:50<02:12,  1.13it/s]
                                                
{'loss': 1.2217, 'grad_norm': 14.776268278833017, 'learning_rate': 4.391782039544239e-06, 'epoch': 0.8}

 25%|██▌       | 50/200 [00:50<02:12,  1.13it/s]
 26%|██▌       | 51/200 [00:51<02:10,  1.14it/s]
                                                
{'loss': 1.188, 'grad_norm': 11.269338643826366, 'learning_rate': 4.365068552858116e-06, 'epoch': 0.82}

 26%|██▌       | 51/200 [00:51<02:10,  1.14it/s]
 26%|██▌       | 52/200 [00:52<02:10,  1.13it/s]
                                                
{'loss': 1.0709, 'grad_norm': 11.512007042750788, 'learning_rate': 4.337865984268002e-06, 'epoch': 0.83}

 26%|██▌       | 52/200 [00:52<02:10,  1.13it/s]
 26%|██▋       | 53/200 [00:53<02:12,  1.11it/s]
                                                
{'loss': 0.9508, 'grad_norm': 11.039448833252147, 'learning_rate': 4.3101814671760546e-06, 'epoch': 0.85}

 26%|██▋       | 53/200 [00:53<02:12,  1.11it/s]
 27%|██▋       | 54/200 [00:54<02:16,  1.07it/s]
                                                
{'loss': 1.0013, 'grad_norm': 9.372426811577613, 'learning_rate': 4.282022261367074e-06, 'epoch': 0.86}

 27%|██▋       | 54/200 [00:54<02:16,  1.07it/s]
 28%|██▊       | 55/200 [00:55<02:13,  1.09it/s]
                                                
{'loss': 0.9249, 'grad_norm': 10.389678131786802, 'learning_rate': 4.2533957511047485e-06, 'epoch': 0.88}

 28%|██▊       | 55/200 [00:55<02:13,  1.09it/s]
 28%|██▊       | 56/200 [00:56<02:09,  1.11it/s]
                                                
{'loss': 1.0235, 'grad_norm': 9.197705057258169, 'learning_rate': 4.224309443195261e-06, 'epoch': 0.9}

 28%|██▊       | 56/200 [00:56<02:09,  1.11it/s]
 28%|██▊       | 57/200 [00:57<02:08,  1.12it/s]
                                                
{'loss': 1.1608, 'grad_norm': 9.056446237063643, 'learning_rate': 4.194770965018758e-06, 'epoch': 0.91}

 28%|██▊       | 57/200 [00:57<02:08,  1.12it/s]
 29%|██▉       | 58/200 [00:57<02:06,  1.12it/s]
                                                
{'loss': 0.9128, 'grad_norm': 8.747482373573357, 'learning_rate': 4.164788062529203e-06, 'epoch': 0.93}

 29%|██▉       | 58/200 [00:57<02:06,  1.12it/s]
 30%|██▉       | 59/200 [00:58<02:04,  1.13it/s]
                                                
{'loss': 0.9083, 'grad_norm': 7.48395398574458, 'learning_rate': 4.134368598223132e-06, 'epoch': 0.94}

 30%|██▉       | 59/200 [00:58<02:04,  1.13it/s]
 30%|███       | 60/200 [00:59<02:03,  1.14it/s]
                                                
{'loss': 0.9, 'grad_norm': 8.856119624156127, 'learning_rate': 4.1035205490778505e-06, 'epoch': 0.96}

 30%|███       | 60/200 [00:59<02:03,  1.14it/s]
 30%|███       | 61/200 [01:00<02:02,  1.14it/s]
                                                
{'loss': 0.9527, 'grad_norm': 7.572499875471354, 'learning_rate': 4.072252004459612e-06, 'epoch': 0.98}

 30%|███       | 61/200 [01:00<02:02,  1.14it/s]
 31%|███       | 62/200 [01:01<02:01,  1.14it/s]
                                                
{'loss': 0.9059, 'grad_norm': 9.688205225716757, 'learning_rate': 4.040571164002319e-06, 'epoch': 0.99}

 31%|███       | 62/200 [01:01<02:01,  1.14it/s]
 32%|███▏      | 63/200 [01:02<02:00,  1.14it/s]
                                                
{'loss': 0.7843, 'grad_norm': 7.4002158777863905, 'learning_rate': 4.008486335457312e-06, 'epoch': 1.01}

 32%|███▏      | 63/200 [01:02<02:00,  1.14it/s]
 32%|███▏      | 64/200 [01:03<01:59,  1.13it/s]
                                                
{'loss': 0.8103, 'grad_norm': 8.337266782046711, 'learning_rate': 3.976005932514807e-06, 'epoch': 1.02}

 32%|███▏      | 64/200 [01:03<01:59,  1.13it/s]
 32%|███▎      | 65/200 [01:04<01:58,  1.14it/s]
                                                
{'loss': 0.8881, 'grad_norm': 8.66495227974476, 'learning_rate': 3.943138472597549e-06, 'epoch': 1.04}

 32%|███▎      | 65/200 [01:04<01:58,  1.14it/s]
 33%|███▎      | 66/200 [01:04<01:58,  1.14it/s]
                                                
{'loss': 0.7795, 'grad_norm': 7.6849795295676, 'learning_rate': 3.909892574627267e-06, 'epoch': 1.06}

 33%|███▎      | 66/200 [01:04<01:58,  1.14it/s]
 34%|███▎      | 67/200 [01:05<01:57,  1.13it/s]
                                                
{'loss': 0.6149, 'grad_norm': 5.433915107487946, 'learning_rate': 3.876276956764509e-06, 'epoch': 1.07}

 34%|███▎      | 67/200 [01:05<01:57,  1.13it/s]
 34%|███▍      | 68/200 [01:06<01:58,  1.12it/s]
                                                
{'loss': 0.7225, 'grad_norm': 6.692142764486831, 'learning_rate': 3.84230043412246e-06, 'epoch': 1.09}

 34%|███▍      | 68/200 [01:06<01:58,  1.12it/s]
 34%|███▍      | 69/200 [01:07<02:00,  1.09it/s]
                                                
{'loss': 0.6957, 'grad_norm': 7.575425129156196, 'learning_rate': 3.807971916455325e-06, 'epoch': 1.1}

 34%|███▍      | 69/200 [01:07<02:00,  1.09it/s]
 35%|███▌      | 70/200 [01:08<01:58,  1.09it/s]
                                                
{'loss': 0.6944, 'grad_norm': 7.582336136644332, 'learning_rate': 3.773300405821908e-06, 'epoch': 1.12}

 35%|███▌      | 70/200 [01:08<01:58,  1.09it/s]
 36%|███▌      | 71/200 [01:09<01:57,  1.10it/s]
                                                
{'loss': 0.4935, 'grad_norm': 5.306052929708777, 'learning_rate': 3.7382949942249695e-06, 'epoch': 1.14}

 36%|███▌      | 71/200 [01:09<01:57,  1.10it/s]
 36%|███▌      | 72/200 [01:10<01:56,  1.09it/s]
                                                
{'loss': 0.6553, 'grad_norm': 6.388793682918583, 'learning_rate': 3.702964861227013e-06, 'epoch': 1.15}

 36%|███▌      | 72/200 [01:10<01:56,  1.09it/s]
 36%|███▋      | 73/200 [01:11<01:54,  1.11it/s]
                                                
{'loss': 0.6991, 'grad_norm': 6.506608977661374, 'learning_rate': 3.6673192715431016e-06, 'epoch': 1.17}

 36%|███▋      | 73/200 [01:11<01:54,  1.11it/s]
 37%|███▋      | 74/200 [01:12<01:52,  1.12it/s]
                                                
{'loss': 0.6075, 'grad_norm': 5.587474691517155, 'learning_rate': 3.631367572611348e-06, 'epoch': 1.18}

 37%|███▋      | 74/200 [01:12<01:52,  1.12it/s]
 38%|███▊      | 75/200 [01:13<01:50,  1.13it/s]
                                                
{'loss': 0.5408, 'grad_norm': 6.261595993123759, 'learning_rate': 3.5951191921417063e-06, 'epoch': 1.2}

 38%|███▊      | 75/200 [01:13<01:50,  1.13it/s]
 38%|███▊      | 76/200 [01:13<01:49,  1.13it/s]
                                                
{'loss': 0.5648, 'grad_norm': 6.40480643034247, 'learning_rate': 3.5585836356437266e-06, 'epoch': 1.22}

 38%|███▊      | 76/200 [01:13<01:49,  1.13it/s]
 38%|███▊      | 77/200 [01:14<01:48,  1.13it/s]
                                                
{'loss': 0.5607, 'grad_norm': 6.034820290507473, 'learning_rate': 3.521770483933891e-06, 'epoch': 1.23}

 38%|███▊      | 77/200 [01:14<01:48,  1.13it/s]
 39%|███▉      | 78/200 [01:15<01:47,  1.13it/s]
                                                
{'loss': 0.5765, 'grad_norm': 6.654396909561412, 'learning_rate': 3.484689390623218e-06, 'epoch': 1.25}

 39%|███▉      | 78/200 [01:15<01:47,  1.13it/s]
 40%|███▉      | 79/200 [01:16<01:47,  1.13it/s]
                                                
{'loss': 0.4422, 'grad_norm': 5.206300425199418, 'learning_rate': 3.4473500795857674e-06, 'epoch': 1.26}

 40%|███▉      | 79/200 [01:16<01:47,  1.13it/s]
 40%|████      | 80/200 [01:17<01:48,  1.10it/s]
                                                
{'loss': 0.5399, 'grad_norm': 6.632629032540625, 'learning_rate': 3.4097623424087196e-06, 'epoch': 1.28}

 40%|████      | 80/200 [01:17<01:48,  1.10it/s]
 40%|████      | 81/200 [01:18<01:46,  1.11it/s]
                                                
{'loss': 0.5172, 'grad_norm': 5.460640960631612, 'learning_rate': 3.3719360358247054e-06, 'epoch': 1.3}

 40%|████      | 81/200 [01:18<01:46,  1.11it/s]
 41%|████      | 82/200 [01:19<01:44,  1.12it/s]
                                                
{'loss': 0.4454, 'grad_norm': 5.660943376083757, 'learning_rate': 3.333881079127052e-06, 'epoch': 1.31}

 41%|████      | 82/200 [01:19<01:44,  1.12it/s]
 42%|████▏     | 83/200 [01:20<01:43,  1.13it/s]
                                                
{'loss': 0.5356, 'grad_norm': 6.864520599896707, 'learning_rate': 3.2956074515686105e-06, 'epoch': 1.33}

 42%|████▏     | 83/200 [01:20<01:43,  1.13it/s]
 42%|████▏     | 84/200 [01:21<01:42,  1.13it/s]
                                                
{'loss': 0.4869, 'grad_norm': 6.106000431704264, 'learning_rate': 3.257125189744877e-06, 'epoch': 1.34}

 42%|████▏     | 84/200 [01:21<01:42,  1.13it/s]
 42%|████▎     | 85/200 [01:21<01:44,  1.10it/s]
                                                
{'loss': 0.433, 'grad_norm': 5.65386997120071, 'learning_rate': 3.218444384962071e-06, 'epoch': 1.36}

 42%|████▎     | 85/200 [01:21<01:44,  1.10it/s]
 43%|████▎     | 86/200 [01:22<01:42,  1.11it/s]
                                                
{'loss': 0.4336, 'grad_norm': 5.821475083134402, 'learning_rate': 3.1795751805908578e-06, 'epoch': 1.38}

 43%|████▎     | 86/200 [01:22<01:42,  1.11it/s]
 44%|████▎     | 87/200 [01:23<01:40,  1.12it/s]
                                                
{'loss': 0.4006, 'grad_norm': 5.74075669089304, 'learning_rate': 3.1405277694064306e-06, 'epoch': 1.39}

 44%|████▎     | 87/200 [01:23<01:40,  1.12it/s]
 44%|████▍     | 88/200 [01:24<01:39,  1.12it/s]
                                                
{'loss': 0.3536, 'grad_norm': 5.162319425883911, 'learning_rate': 3.1013123909156347e-06, 'epoch': 1.41}

 44%|████▍     | 88/200 [01:24<01:39,  1.12it/s]
 44%|████▍     | 89/200 [01:25<01:39,  1.12it/s]
                                                
{'loss': 0.4309, 'grad_norm': 5.821932450736396, 'learning_rate': 3.061939328671824e-06, 'epoch': 1.42}

 44%|████▍     | 89/200 [01:25<01:39,  1.12it/s]
 45%|████▌     | 90/200 [01:26<01:45,  1.04it/s]
                                                
{'loss': 0.3948, 'grad_norm': 5.610740559159048, 'learning_rate': 3.0224189075781886e-06, 'epoch': 1.44}

 45%|████▌     | 90/200 [01:26<01:45,  1.04it/s]
 46%|████▌     | 91/200 [01:27<01:42,  1.06it/s]
                                                
{'loss': 0.3723, 'grad_norm': 5.868303418865553, 'learning_rate': 2.9827614911802205e-06, 'epoch': 1.46}

 46%|████▌     | 91/200 [01:27<01:42,  1.06it/s]
 46%|████▌     | 92/200 [01:28<01:39,  1.08it/s]
                                                
{'loss': 0.3444, 'grad_norm': 4.937468516575357, 'learning_rate': 2.9429774789480576e-06, 'epoch': 1.47}

 46%|████▌     | 92/200 [01:28<01:39,  1.08it/s]
 46%|████▋     | 93/200 [01:29<01:38,  1.09it/s]
                                                
{'loss': 0.3455, 'grad_norm': 4.543980257058572, 'learning_rate': 2.9030773035493997e-06, 'epoch': 1.49}

 46%|████▋     | 93/200 [01:29<01:38,  1.09it/s]
 47%|████▋     | 94/200 [01:30<01:35,  1.11it/s]
                                                
{'loss': 0.3537, 'grad_norm': 6.112845057321854, 'learning_rate': 2.8630714281137263e-06, 'epoch': 1.5}

 47%|████▋     | 94/200 [01:30<01:35,  1.11it/s]
 48%|████▊     | 95/200 [01:31<01:33,  1.12it/s]
                                                
{'loss': 0.4186, 'grad_norm': 8.567333333042034, 'learning_rate': 2.8229703434885165e-06, 'epoch': 1.52}

 48%|████▊     | 95/200 [01:31<01:33,  1.12it/s]
 48%|████▊     | 96/200 [01:31<01:32,  1.12it/s]
                                                
{'loss': 0.2953, 'grad_norm': 5.00889597105759, 'learning_rate': 2.7827845654882112e-06, 'epoch': 1.54}

 48%|████▊     | 96/200 [01:31<01:32,  1.12it/s]
 48%|████▊     | 97/200 [01:32<01:31,  1.13it/s]
                                                
{'loss': 0.3254, 'grad_norm': 6.33278938099114, 'learning_rate': 2.7425246321366205e-06, 'epoch': 1.55}

 48%|████▊     | 97/200 [01:32<01:31,  1.13it/s]
 49%|████▉     | 98/200 [01:33<01:30,  1.12it/s]
                                                
{'loss': 0.3034, 'grad_norm': 5.336005236976261, 'learning_rate': 2.702201100903511e-06, 'epoch': 1.57}

 49%|████▉     | 98/200 [01:33<01:30,  1.12it/s]
 50%|████▉     | 99/200 [01:34<01:29,  1.13it/s]
                                                
{'loss': 0.2277, 'grad_norm': 4.074141972550785, 'learning_rate': 2.6618245459360896e-06, 'epoch': 1.58}

 50%|████▉     | 99/200 [01:34<01:29,  1.13it/s]
 50%|█████     | 100/200 [01:35<01:28,  1.13it/s]
                                                 
{'loss': 0.271, 'grad_norm': 5.155972929937477, 'learning_rate': 2.6214055552861213e-06, 'epoch': 1.6}

 50%|█████     | 100/200 [01:35<01:28,  1.13it/s]
 50%|█████     | 101/200 [01:36<01:27,  1.13it/s]
                                                 
{'loss': 0.2622, 'grad_norm': 4.944033199643264, 'learning_rate': 2.5809547281333904e-06, 'epoch': 1.62}

 50%|█████     | 101/200 [01:37<01:27,  1.13it/s]
 51%|█████     | 102/200 [01:37<01:47,  1.10s/it]
                                                 
{'loss': 0.2347, 'grad_norm': 5.657369091965329, 'learning_rate': 2.5404826720062544e-06, 'epoch': 1.63}

 51%|█████     | 102/200 [01:37<01:47,  1.10s/it]
 52%|█████▏    | 103/200 [01:38<01:41,  1.04s/it]
                                                 
{'loss': 0.2516, 'grad_norm': 5.4117588795633, 'learning_rate': 2.5e-06, 'epoch': 1.65}

 52%|█████▏    | 103/200 [01:38<01:41,  1.04s/it]
 52%|█████▏    | 104/200 [01:39<01:36,  1.00s/it]
                                                 
{'loss': 0.2502, 'grad_norm': 5.322238567878472, 'learning_rate': 2.4595173279937464e-06, 'epoch': 1.66}

 52%|█████▏    | 104/200 [01:39<01:36,  1.00s/it]
 52%|█████▎    | 105/200 [01:40<01:31,  1.04it/s]
                                                 
{'loss': 0.2533, 'grad_norm': 5.925925125457568, 'learning_rate': 2.419045271866611e-06, 'epoch': 1.68}

 52%|█████▎    | 105/200 [01:40<01:31,  1.04it/s]
 53%|█████▎    | 106/200 [01:41<01:28,  1.06it/s]
                                                 
{'loss': 0.2116, 'grad_norm': 5.27099842320612, 'learning_rate': 2.3785944447138804e-06, 'epoch': 1.7}

 53%|█████▎    | 106/200 [01:42<01:28,  1.06it/s]
 54%|█████▎    | 107/200 [01:43<01:43,  1.11s/it]
                                                 
{'loss': 0.2151, 'grad_norm': 5.946759202063273, 'learning_rate': 2.3381754540639108e-06, 'epoch': 1.71}

 54%|█████▎    | 107/200 [01:43<01:43,  1.11s/it]
 54%|█████▍    | 108/200 [01:43<01:35,  1.04s/it]
                                                 
{'loss': 0.1873, 'grad_norm': 5.792905862457876, 'learning_rate': 2.29779889909649e-06, 'epoch': 1.73}

 54%|█████▍    | 108/200 [01:43<01:35,  1.04s/it]
 55%|█████▍    | 109/200 [01:44<01:30,  1.00it/s]
                                                 
{'loss': 0.2229, 'grad_norm': 6.218719635702409, 'learning_rate': 2.25747536786338e-06, 'epoch': 1.74}

 55%|█████▍    | 109/200 [01:44<01:30,  1.00it/s]
 55%|█████▌    | 110/200 [01:45<01:26,  1.04it/s]
                                                 
{'loss': 0.1474, 'grad_norm': 4.841486051060892, 'learning_rate': 2.2172154345117896e-06, 'epoch': 1.76}

 55%|█████▌    | 110/200 [01:45<01:26,  1.04it/s]
 56%|█████▌    | 111/200 [01:46<01:25,  1.04it/s]
                                                 
{'loss': 0.1277, 'grad_norm': 4.68022099225848, 'learning_rate': 2.1770296565114847e-06, 'epoch': 1.78}

 56%|█████▌    | 111/200 [01:46<01:25,  1.04it/s]
 56%|█████▌    | 112/200 [01:47<01:22,  1.07it/s]
                                                 
{'loss': 0.1807, 'grad_norm': 5.482956923036424, 'learning_rate': 2.136928571886275e-06, 'epoch': 1.79}

 56%|█████▌    | 112/200 [01:47<01:22,  1.07it/s]
 56%|█████▋    | 113/200 [01:48<01:19,  1.09it/s]
                                                 
{'loss': 0.1501, 'grad_norm': 5.136039381464486, 'learning_rate': 2.0969226964506007e-06, 'epoch': 1.81}

 56%|█████▋    | 113/200 [01:48<01:19,  1.09it/s]
 57%|█████▋    | 114/200 [01:49<01:17,  1.11it/s]
                                                 
{'loss': 0.1518, 'grad_norm': 5.608757473843082, 'learning_rate': 2.0570225210519433e-06, 'epoch': 1.82}

 57%|█████▋    | 114/200 [01:49<01:17,  1.11it/s]
 57%|█████▊    | 115/200 [01:50<01:16,  1.11it/s]
                                                 
{'loss': 0.1468, 'grad_norm': 4.680879316945649, 'learning_rate': 2.0172385088197804e-06, 'epoch': 1.84}

 57%|█████▊    | 115/200 [01:50<01:16,  1.11it/s]
 58%|█████▊    | 116/200 [01:51<01:14,  1.12it/s]
                                                 
{'loss': 0.131, 'grad_norm': 5.410698267918843, 'learning_rate': 1.9775810924218126e-06, 'epoch': 1.86}

 58%|█████▊    | 116/200 [01:51<01:14,  1.12it/s]
 58%|█████▊    | 117/200 [01:51<01:13,  1.13it/s]
                                                 
{'loss': 0.1444, 'grad_norm': 6.389589855421693, 'learning_rate': 1.9380606713281773e-06, 'epoch': 1.87}

 58%|█████▊    | 117/200 [01:51<01:13,  1.13it/s]
 59%|█████▉    | 118/200 [01:52<01:12,  1.13it/s]
                                                 
{'loss': 0.1236, 'grad_norm': 5.261685762818832, 'learning_rate': 1.8986876090843668e-06, 'epoch': 1.89}

 59%|█████▉    | 118/200 [01:52<01:12,  1.13it/s]
 60%|█████▉    | 119/200 [01:53<01:11,  1.13it/s]
                                                 
{'loss': 0.1084, 'grad_norm': 4.854982408517225, 'learning_rate': 1.8594722305935691e-06, 'epoch': 1.9}

 60%|█████▉    | 119/200 [01:53<01:11,  1.13it/s]
 60%|██████    | 120/200 [01:54<01:10,  1.13it/s]
                                                 
{'loss': 0.0909, 'grad_norm': 4.624508393425119, 'learning_rate': 1.8204248194091429e-06, 'epoch': 1.92}

 60%|██████    | 120/200 [01:54<01:10,  1.13it/s]
 60%|██████    | 121/200 [01:55<01:09,  1.13it/s]
                                                 
{'loss': 0.1056, 'grad_norm': 4.489629026860474, 'learning_rate': 1.7815556150379298e-06, 'epoch': 1.94}

 60%|██████    | 121/200 [01:55<01:09,  1.13it/s]
 61%|██████    | 122/200 [01:56<01:08,  1.13it/s]
                                                 
{'loss': 0.1025, 'grad_norm': 4.278469547193221, 'learning_rate': 1.7428748102551237e-06, 'epoch': 1.95}

 61%|██████    | 122/200 [01:56<01:08,  1.13it/s]
 62%|██████▏   | 123/200 [01:57<01:09,  1.10it/s]
                                                 
{'loss': 0.098, 'grad_norm': 4.075833082171141, 'learning_rate': 1.7043925484313911e-06, 'epoch': 1.97}

 62%|██████▏   | 123/200 [01:57<01:09,  1.10it/s]
 62%|██████▏   | 124/200 [01:58<01:08,  1.11it/s]
                                                 
{'loss': 0.0876, 'grad_norm': 3.7519757470199067, 'learning_rate': 1.6661189208729492e-06, 'epoch': 1.98}

 62%|██████▏   | 124/200 [01:58<01:08,  1.11it/s]
 62%|██████▎   | 125/200 [01:59<01:07,  1.11it/s]
                                                 
{'loss': 0.0792, 'grad_norm': 3.842347300069715, 'learning_rate': 1.6280639641752944e-06, 'epoch': 2.0}

 62%|██████▎   | 125/200 [01:59<01:07,  1.11it/s]
 63%|██████▎   | 126/200 [01:59<01:06,  1.12it/s]
                                                 
{'loss': 0.0537, 'grad_norm': 3.456302613449422, 'learning_rate': 1.5902376575912815e-06, 'epoch': 2.02}

 63%|██████▎   | 126/200 [01:59<01:06,  1.12it/s]
 64%|██████▎   | 127/200 [02:00<01:05,  1.11it/s]
                                                 
{'loss': 0.072, 'grad_norm': 3.844479871475169, 'learning_rate': 1.5526499204142332e-06, 'epoch': 2.03}

 64%|██████▎   | 127/200 [02:00<01:05,  1.11it/s]
 64%|██████▍   | 128/200 [02:01<01:05,  1.10it/s]
                                                 
{'loss': 0.0663, 'grad_norm': 3.4716805116032776, 'learning_rate': 1.5153106093767827e-06, 'epoch': 2.05}

 64%|██████▍   | 128/200 [02:01<01:05,  1.10it/s]
 64%|██████▍   | 129/200 [02:02<01:04,  1.09it/s]
                                                 
{'loss': 0.0634, 'grad_norm': 3.032253295977161, 'learning_rate': 1.4782295160661103e-06, 'epoch': 2.06}

 64%|██████▍   | 129/200 [02:02<01:04,  1.09it/s]
 65%|██████▌   | 130/200 [02:03<01:03,  1.10it/s]
                                                 
{'loss': 0.0572, 'grad_norm': 3.09573793602273, 'learning_rate': 1.4414163643562755e-06, 'epoch': 2.08}

 65%|██████▌   | 130/200 [02:03<01:03,  1.10it/s]
 66%|██████▌   | 131/200 [02:04<01:02,  1.11it/s]
                                                 
{'loss': 0.0713, 'grad_norm': 3.4290693069177687, 'learning_rate': 1.4048808078582943e-06, 'epoch': 2.1}

 66%|██████▌   | 131/200 [02:04<01:02,  1.11it/s]
 66%|██████▌   | 132/200 [02:05<01:01,  1.11it/s]
                                                 
{'loss': 0.049, 'grad_norm': 2.9529280016551342, 'learning_rate': 1.3686324273886531e-06, 'epoch': 2.11}

 66%|██████▌   | 132/200 [02:05<01:01,  1.11it/s]
 66%|██████▋   | 133/200 [02:06<00:59,  1.12it/s]
                                                 
{'loss': 0.0528, 'grad_norm': 3.1465601470935436, 'learning_rate': 1.3326807284568984e-06, 'epoch': 2.13}

 66%|██████▋   | 133/200 [02:06<00:59,  1.12it/s]
 67%|██████▋   | 134/200 [02:07<00:58,  1.12it/s]
                                                 
{'loss': 0.0438, 'grad_norm': 2.8513785525002118, 'learning_rate': 1.2970351387729875e-06, 'epoch': 2.14}

 67%|██████▋   | 134/200 [02:07<00:58,  1.12it/s]
 68%|██████▊   | 135/200 [02:08<00:57,  1.13it/s]
                                                 
{'loss': 0.0317, 'grad_norm': 2.292781269785743, 'learning_rate': 1.2617050057750322e-06, 'epoch': 2.16}

 68%|██████▊   | 135/200 [02:08<00:57,  1.13it/s]
 68%|██████▊   | 136/200 [02:08<00:57,  1.12it/s]
                                                 
{'loss': 0.0392, 'grad_norm': 2.7413305263981136, 'learning_rate': 1.2266995941780934e-06, 'epoch': 2.18}

 68%|██████▊   | 136/200 [02:08<00:57,  1.12it/s]
 68%|██████▊   | 137/200 [02:09<00:56,  1.12it/s]
                                                 
{'loss': 0.0482, 'grad_norm': 2.7269834177137637, 'learning_rate': 1.192028083544675e-06, 'epoch': 2.19}

 68%|██████▊   | 137/200 [02:09<00:56,  1.12it/s]
 69%|██████▉   | 138/200 [02:10<00:54,  1.13it/s]
                                                 
{'loss': 0.0385, 'grad_norm': 2.5144060866226092, 'learning_rate': 1.1576995658775405e-06, 'epoch': 2.21}

 69%|██████▉   | 138/200 [02:10<00:54,  1.13it/s]
 70%|██████▉   | 139/200 [02:11<00:55,  1.10it/s]
                                                 
{'loss': 0.024, 'grad_norm': 1.9691911838838587, 'learning_rate': 1.1237230432354912e-06, 'epoch': 2.22}

 70%|██████▉   | 139/200 [02:11<00:55,  1.10it/s]
 70%|███████   | 140/200 [02:12<00:54,  1.10it/s]
                                                 
{'loss': 0.0327, 'grad_norm': 2.396197139373847, 'learning_rate': 1.0901074253727338e-06, 'epoch': 2.24}

 70%|███████   | 140/200 [02:12<00:54,  1.10it/s]
 70%|███████   | 141/200 [02:13<00:52,  1.12it/s]
                                                 
{'loss': 0.0366, 'grad_norm': 2.3788444122645878, 'learning_rate': 1.0568615274024521e-06, 'epoch': 2.26}

 70%|███████   | 141/200 [02:13<00:52,  1.12it/s]
 71%|███████   | 142/200 [02:14<00:51,  1.13it/s]
                                                 
{'loss': 0.0351, 'grad_norm': 2.4911873942316567, 'learning_rate': 1.0239940674851943e-06, 'epoch': 2.27}

 71%|███████   | 142/200 [02:14<00:51,  1.13it/s]
 72%|███████▏  | 143/200 [02:15<00:50,  1.13it/s]
                                                 
{'loss': 0.0215, 'grad_norm': 1.6002666161843613, 'learning_rate': 9.915136645426885e-07, 'epoch': 2.29}

 72%|███████▏  | 143/200 [02:15<00:50,  1.13it/s]
 72%|███████▏  | 144/200 [02:16<00:49,  1.13it/s]
                                                 
{'loss': 0.018, 'grad_norm': 1.3779794317684249, 'learning_rate': 9.594288359976817e-07, 'epoch': 2.3}

 72%|███████▏  | 144/200 [02:16<00:49,  1.13it/s]
 72%|███████▎  | 145/200 [02:16<00:48,  1.13it/s]
                                                 
{'loss': 0.0315, 'grad_norm': 2.0536315293136007, 'learning_rate': 9.277479955403887e-07, 'epoch': 2.32}

 72%|███████▎  | 145/200 [02:16<00:48,  1.13it/s]
 73%|███████▎  | 146/200 [02:17<00:48,  1.12it/s]
                                                 
{'loss': 0.0268, 'grad_norm': 1.6527989980081583, 'learning_rate': 8.964794509221508e-07, 'epoch': 2.34}

 73%|███████▎  | 146/200 [02:17<00:48,  1.12it/s]
 74%|███████▎  | 147/200 [02:18<00:47,  1.11it/s]
                                                 
{'loss': 0.025, 'grad_norm': 1.6324990441639367, 'learning_rate': 8.656314017768694e-07, 'epoch': 2.35}

 74%|███████▎  | 147/200 [02:18<00:47,  1.11it/s]
 74%|███████▍  | 148/200 [02:19<00:46,  1.12it/s]
                                                 
{'loss': 0.0242, 'grad_norm': 1.6845488704477765, 'learning_rate': 8.352119374707979e-07, 'epoch': 2.37}

 74%|███████▍  | 148/200 [02:19<00:46,  1.12it/s]
 74%|███████▍  | 149/200 [02:20<00:45,  1.12it/s]
                                                 
{'loss': 0.0336, 'grad_norm': 1.8649333291498846, 'learning_rate': 8.052290349812419e-07, 'epoch': 2.38}

 74%|███████▍  | 149/200 [02:20<00:45,  1.12it/s]
 75%|███████▌  | 150/200 [02:21<00:44,  1.13it/s]
                                                 
{'loss': 0.0135, 'grad_norm': 0.991881405930484, 'learning_rate': 7.756905568047393e-07, 'epoch': 2.4}

 75%|███████▌  | 150/200 [02:21<00:44,  1.13it/s]
 76%|███████▌  | 151/200 [02:22<00:43,  1.13it/s]
                                                 
{'loss': 0.0196, 'grad_norm': 1.4689782959468844, 'learning_rate': 7.466042488952521e-07, 'epoch': 2.42}

 76%|███████▌  | 151/200 [02:22<00:43,  1.13it/s]
 76%|███████▌  | 152/200 [02:23<00:42,  1.13it/s]
                                                 
{'loss': 0.0195, 'grad_norm': 1.6757134555005753, 'learning_rate': 7.179777386329276e-07, 'epoch': 2.43}

 76%|███████▌  | 152/200 [02:23<00:42,  1.13it/s]
 76%|███████▋  | 153/200 [02:24<00:41,  1.13it/s]
                                                 
{'loss': 0.0203, 'grad_norm': 1.324078397711685, 'learning_rate': 6.898185328239468e-07, 'epoch': 2.45}

 76%|███████▋  | 153/200 [02:24<00:41,  1.13it/s]
 77%|███████▋  | 154/200 [02:24<00:40,  1.13it/s]
                                                 
{'loss': 0.0189, 'grad_norm': 1.5871568323917804, 'learning_rate': 6.621340157319998e-07, 'epoch': 2.46}

 77%|███████▋  | 154/200 [02:24<00:40,  1.13it/s]
 78%|███████▊  | 155/200 [02:25<00:40,  1.10it/s]
                                                 
{'loss': 0.012, 'grad_norm': 0.9426630581825377, 'learning_rate': 6.349314471418849e-07, 'epoch': 2.48}

 78%|███████▊  | 155/200 [02:25<00:40,  1.10it/s]
 78%|███████▊  | 156/200 [02:26<00:40,  1.08it/s]
                                                 
{'loss': 0.0171, 'grad_norm': 1.1614040253719402, 'learning_rate': 6.082179604557617e-07, 'epoch': 2.5}

 78%|███████▊  | 156/200 [02:26<00:40,  1.08it/s]
 78%|███████▊  | 157/200 [02:27<00:39,  1.10it/s]
                                                 
{'loss': 0.0264, 'grad_norm': 1.8940227022633185, 'learning_rate': 5.820005608225345e-07, 'epoch': 2.51}

 78%|███████▊  | 157/200 [02:27<00:39,  1.10it/s]
 79%|███████▉  | 158/200 [02:28<00:37,  1.11it/s]
                                                 
{'loss': 0.0154, 'grad_norm': 1.1753850630593417, 'learning_rate': 5.562861233008774e-07, 'epoch': 2.53}

 79%|███████▉  | 158/200 [02:28<00:37,  1.11it/s]
 80%|███████▉  | 159/200 [02:29<00:36,  1.12it/s]
                                                 
{'loss': 0.0146, 'grad_norm': 1.087423063165594, 'learning_rate': 5.310813910563645e-07, 'epoch': 2.54}

 80%|███████▉  | 159/200 [02:29<00:36,  1.12it/s]
 80%|████████  | 160/200 [02:30<00:35,  1.13it/s]
                                                 
{'loss': 0.0186, 'grad_norm': 1.3996596723116634, 'learning_rate': 5.063929735931985e-07, 'epoch': 2.56}

 80%|████████  | 160/200 [02:30<00:35,  1.13it/s]
 80%|████████  | 161/200 [02:31<00:34,  1.12it/s]
                                                 
{'loss': 0.015, 'grad_norm': 1.1134859666492456, 'learning_rate': 4.822273450209767e-07, 'epoch': 2.58}

 80%|████████  | 161/200 [02:31<00:34,  1.12it/s]
 81%|████████  | 162/200 [02:32<00:33,  1.13it/s]
                                                 
{'loss': 0.0157, 'grad_norm': 1.2452510746796341, 'learning_rate': 4.5859084235697236e-07, 'epoch': 2.59}

 81%|████████  | 162/200 [02:32<00:33,  1.13it/s]
 82%|████████▏ | 163/200 [02:33<00:33,  1.12it/s]
                                                 
{'loss': 0.0128, 'grad_norm': 1.092353365068294, 'learning_rate': 4.354896638643591e-07, 'epoch': 2.61}

 82%|████████▏ | 163/200 [02:33<00:33,  1.12it/s]
 82%|████████▏ | 164/200 [02:33<00:31,  1.13it/s]
                                                 
{'loss': 0.0195, 'grad_norm': 1.8595125804618133, 'learning_rate': 4.129298674268226e-07, 'epoch': 2.62}

 82%|████████▏ | 164/200 [02:33<00:31,  1.13it/s]
 82%|████████▎ | 165/200 [02:34<00:31,  1.12it/s]
                                                 
{'loss': 0.0176, 'grad_norm': 1.2237077280600908, 'learning_rate': 3.9091736895998907e-07, 'epoch': 2.64}

 82%|████████▎ | 165/200 [02:34<00:31,  1.12it/s]
 83%|████████▎ | 166/200 [02:35<00:30,  1.13it/s]
                                                 
{'loss': 0.0121, 'grad_norm': 0.9963134822458932, 'learning_rate': 3.6945794086007706e-07, 'epoch': 2.66}

 83%|████████▎ | 166/200 [02:35<00:30,  1.13it/s]
 84%|████████▎ | 167/200 [02:36<00:29,  1.13it/s]
                                                 
{'loss': 0.0109, 'grad_norm': 0.865403100778126, 'learning_rate': 3.485572104901869e-07, 'epoch': 2.67}

 84%|████████▎ | 167/200 [02:36<00:29,  1.13it/s]
 84%|████████▍ | 168/200 [02:37<00:28,  1.13it/s]
                                                 
{'loss': 0.0083, 'grad_norm': 0.8044162404144759, 'learning_rate': 3.2822065870462216e-07, 'epoch': 2.69}

 84%|████████▍ | 168/200 [02:37<00:28,  1.13it/s]
 84%|████████▍ | 169/200 [02:38<00:27,  1.13it/s]
                                                 
{'loss': 0.0141, 'grad_norm': 1.128899914152852, 'learning_rate': 3.08453618411631e-07, 'epoch': 2.7}

 84%|████████▍ | 169/200 [02:38<00:27,  1.13it/s]
 85%|████████▌ | 170/200 [02:39<00:26,  1.13it/s]
                                                 
{'loss': 0.0171, 'grad_norm': 1.2061307937146082, 'learning_rate': 2.892612731749414e-07, 'epoch': 2.72}

 85%|████████▌ | 170/200 [02:39<00:26,  1.13it/s]
 86%|████████▌ | 171/200 [02:40<00:25,  1.12it/s]
                                                 
{'loss': 0.0081, 'grad_norm': 0.7608654622595201, 'learning_rate': 2.706486558544644e-07, 'epoch': 2.74}

 86%|████████▌ | 171/200 [02:40<00:25,  1.12it/s]
 86%|████████▌ | 172/200 [02:41<00:24,  1.13it/s]
                                                 
{'loss': 0.0153, 'grad_norm': 1.7079451360266236, 'learning_rate': 2.52620647286512e-07, 'epoch': 2.75}

 86%|████████▌ | 172/200 [02:41<00:24,  1.13it/s]
 86%|████████▋ | 173/200 [02:41<00:24,  1.12it/s]
                                                 
{'loss': 0.0117, 'grad_norm': 0.8390131191732925, 'learning_rate': 2.3518197500388278e-07, 'epoch': 2.77}

 86%|████████▋ | 173/200 [02:41<00:24,  1.12it/s]
 87%|████████▋ | 174/200 [02:42<00:23,  1.12it/s]
                                                 
{'loss': 0.0115, 'grad_norm': 1.0878483269240053, 'learning_rate': 2.1833721199614992e-07, 'epoch': 2.78}

 87%|████████▋ | 174/200 [02:42<00:23,  1.12it/s]
 88%|████████▊ | 175/200 [02:43<00:22,  1.13it/s]
                                                 
{'loss': 0.0126, 'grad_norm': 1.290967747064533, 'learning_rate': 2.020907755104698e-07, 'epoch': 2.8}

 88%|████████▊ | 175/200 [02:43<00:22,  1.13it/s]
 88%|████████▊ | 176/200 [02:44<00:21,  1.12it/s]
                                                 
{'loss': 0.0128, 'grad_norm': 1.1266011923231238, 'learning_rate': 1.864469258932397e-07, 'epoch': 2.82}

 88%|████████▊ | 176/200 [02:44<00:21,  1.12it/s]
 88%|████████▊ | 177/200 [02:45<00:20,  1.12it/s]
                                                 
{'loss': 0.0073, 'grad_norm': 0.7409844938424142, 'learning_rate': 1.7140976547289438e-07, 'epoch': 2.83}

 88%|████████▊ | 177/200 [02:45<00:20,  1.12it/s]
 89%|████████▉ | 178/200 [02:46<00:19,  1.13it/s]
                                                 
{'loss': 0.0085, 'grad_norm': 0.6403657342053145, 'learning_rate': 1.5698323748414123e-07, 'epoch': 2.85}

 89%|████████▉ | 178/200 [02:46<00:19,  1.13it/s]
 90%|████████▉ | 179/200 [02:47<00:18,  1.13it/s]
                                                 
{'loss': 0.0074, 'grad_norm': 0.8173467885673572, 'learning_rate': 1.4317112503391433e-07, 'epoch': 2.86}

 90%|████████▉ | 179/200 [02:47<00:18,  1.13it/s]
 90%|█████████ | 180/200 [02:48<00:17,  1.13it/s]
                                                 
{'loss': 0.0168, 'grad_norm': 1.4472999723119344, 'learning_rate': 1.2997705010932394e-07, 'epoch': 2.88}

 90%|█████████ | 180/200 [02:48<00:17,  1.13it/s]
 90%|█████████ | 181/200 [02:49<00:17,  1.09it/s]
                                                 
{'loss': 0.0107, 'grad_norm': 1.1177255895206293, 'learning_rate': 1.1740447262784782e-07, 'epoch': 2.9}

 90%|█████████ | 181/200 [02:49<00:17,  1.09it/s]
 91%|█████████ | 182/200 [02:50<00:16,  1.10it/s]
                                                 
{'loss': 0.0118, 'grad_norm': 0.9213192444532406, 'learning_rate': 1.054566895300324e-07, 'epoch': 2.91}

 91%|█████████ | 182/200 [02:50<00:16,  1.10it/s]
 92%|█████████▏| 183/200 [02:50<00:15,  1.11it/s]
                                                 
{'loss': 0.0076, 'grad_norm': 0.649619667948864, 'learning_rate': 9.413683391492456e-08, 'epoch': 2.93}

 92%|█████████▏| 183/200 [02:50<00:15,  1.11it/s]
 92%|█████████▏| 184/200 [02:51<00:14,  1.12it/s]
                                                 
{'loss': 0.0161, 'grad_norm': 1.4082745707213944, 'learning_rate': 8.344787421847216e-08, 'epoch': 2.94}

 92%|█████████▏| 184/200 [02:51<00:14,  1.12it/s]
 92%|█████████▎| 185/200 [02:52<00:13,  1.13it/s]
                                                 
{'loss': 0.0123, 'grad_norm': 1.0151554489426156, 'learning_rate': 7.339261343510207e-08, 'epoch': 2.96}

 92%|█████████▎| 185/200 [02:52<00:13,  1.13it/s]
 93%|█████████▎| 186/200 [02:53<00:12,  1.12it/s]
                                                 
{'loss': 0.0131, 'grad_norm': 1.2956620484431656, 'learning_rate': 6.397368838268497e-08, 'epoch': 2.98}

 93%|█████████▎| 186/200 [02:53<00:12,  1.12it/s]
 94%|█████████▎| 187/200 [02:54<00:11,  1.13it/s]
                                                 
{'loss': 0.0102, 'grad_norm': 0.6739344416240022, 'learning_rate': 5.519356901107359e-08, 'epoch': 2.99}

 94%|█████████▎| 187/200 [02:54<00:11,  1.13it/s]
 94%|█████████▍| 188/200 [02:55<00:10,  1.13it/s]
                                                 
{'loss': 0.0088, 'grad_norm': 0.7506790663204382, 'learning_rate': 4.705455775440237e-08, 'epoch': 3.01}

 94%|█████████▍| 188/200 [02:55<00:10,  1.13it/s]
 94%|█████████▍| 189/200 [02:56<00:09,  1.13it/s]
                                                 
{'loss': 0.007, 'grad_norm': 0.561450031292271, 'learning_rate': 3.955878892731441e-08, 'epoch': 3.02}

 94%|█████████▍| 189/200 [02:56<00:09,  1.13it/s]
 95%|█████████▌| 190/200 [02:57<00:09,  1.10it/s]
                                                 
{'loss': 0.0096, 'grad_norm': 0.9754299462962631, 'learning_rate': 3.270822816527325e-08, 'epoch': 3.04}

 95%|█████████▌| 190/200 [02:57<00:09,  1.10it/s]
 96%|█████████▌| 191/200 [02:58<00:08,  1.11it/s]
                                                 
{'loss': 0.0077, 'grad_norm': 0.6853843561536076, 'learning_rate': 2.6504671909109993e-08, 'epoch': 3.06}

 96%|█████████▌| 191/200 [02:58<00:08,  1.11it/s]
 96%|█████████▌| 192/200 [02:58<00:07,  1.12it/s]
                                                 
{'loss': 0.0242, 'grad_norm': 0.9607545942206103, 'learning_rate': 2.094974693393731e-08, 'epoch': 3.07}

 96%|█████████▌| 192/200 [02:58<00:07,  1.12it/s]
 96%|█████████▋| 193/200 [02:59<00:06,  1.13it/s]
                                                 
{'loss': 0.0183, 'grad_norm': 1.46395594841183, 'learning_rate': 1.6044909922555973e-08, 'epoch': 3.09}

 96%|█████████▋| 193/200 [02:59<00:06,  1.13it/s]
 97%|█████████▋| 194/200 [03:00<00:05,  1.13it/s]
                                                 
{'loss': 0.0125, 'grad_norm': 0.9618971769913098, 'learning_rate': 1.1791447083465136e-08, 'epoch': 3.1}

 97%|█████████▋| 194/200 [03:00<00:05,  1.13it/s]
 98%|█████████▊| 195/200 [03:01<00:04,  1.14it/s]
                                                 
{'loss': 0.0084, 'grad_norm': 0.6753693356090223, 'learning_rate': 8.190473813576571e-09, 'epoch': 3.12}

 98%|█████████▊| 195/200 [03:01<00:04,  1.14it/s]
 98%|█████████▊| 196/200 [03:02<00:03,  1.13it/s]
                                                 
{'loss': 0.0143, 'grad_norm': 1.148686596072268, 'learning_rate': 5.242934405720879e-09, 'epoch': 3.14}

 98%|█████████▊| 196/200 [03:02<00:03,  1.13it/s]
 98%|█████████▊| 197/200 [03:03<00:02,  1.13it/s]
                                                 
{'loss': 0.0068, 'grad_norm': 0.6407830578346675, 'learning_rate': 2.9496018010233275e-09, 'epoch': 3.15}

 98%|█████████▊| 197/200 [03:03<00:02,  1.13it/s]
 99%|█████████▉| 198/200 [03:04<00:01,  1.13it/s]
                                                 
{'loss': 0.0108, 'grad_norm': 0.9922217415735728, 'learning_rate': 1.3110773862126669e-09, 'epoch': 3.17}

 99%|█████████▉| 198/200 [03:04<00:01,  1.13it/s]
100%|█████████▉| 199/200 [03:05<00:00,  1.13it/s]
                                                 
{'loss': 0.0114, 'grad_norm': 1.4131327570584638, 'learning_rate': 3.277908359194948e-10, 'epoch': 3.18}

100%|█████████▉| 199/200 [03:05<00:00,  1.13it/s]
100%|██████████| 200/200 [03:06<00:00,  1.11it/s]
                                                 
{'loss': 0.0112, 'grad_norm': 0.8591665535330737, 'learning_rate': 0.0, 'epoch': 3.2}

100%|██████████| 200/200 [03:06<00:00,  1.11it/s]/work/.env/openmind_finetune/lib/python3.10/site-packages/peft/utils/save_and_load.py:257: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.
  warnings.warn(
/work/.env/openmind_finetune/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/work/.env/openmind_finetune/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/work/.env/openmind_finetune/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/work/.env/openmind_finetune/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/work/.env/openmind_finetune/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/work/.env/openmind_finetune/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/work/.env/openmind_finetune/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/work/.env/openmind_finetune/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(

                                                 
{'train_runtime': 213.9701, 'train_samples_per_second': 59.821, 'train_steps_per_second': 0.935, 'train_loss': 0.6591836604685523, 'epoch': 3.2}

100%|██████████| 200/200 [03:33<00:00,  1.11it/s]
100%|██████████| 200/200 [03:33<00:00,  1.07s/it]
/work/.env/openmind_finetune/lib/python3.10/site-packages/peft/utils/save_and_load.py:257: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.
  warnings.warn(
Repo card metadata block was not found. Setting CardData to empty.
Repo card metadata block was not found. Setting CardData to empty.
Repo card metadata block was not found. Setting CardData to empty.
Repo card metadata block was not found. Setting CardData to empty.
Repo card metadata block was not found. Setting CardData to empty.
/work/.env/openmind_finetune/lib/python3.10/site-packages/peft/utils/save_and_load.py:257: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.
  warnings.warn(
/work/.env/openmind_finetune/lib/python3.10/site-packages/peft/utils/save_and_load.py:257: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.
  warnings.warn(
/work/.env/openmind_finetune/lib/python3.10/site-packages/peft/utils/save_and_load.py:257: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.
  warnings.warn(
/work/.env/openmind_finetune/lib/python3.10/site-packages/peft/utils/save_and_load.py:257: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.
  warnings.warn(
/work/.env/openmind_finetune/lib/python3.10/site-packages/peft/utils/save_and_load.py:257: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.
  warnings.warn(
/work/.env/openmind_finetune/lib/python3.10/site-packages/peft/utils/save_and_load.py:257: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.
  warnings.warn(
