Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
Loading checkpoint shards:  25%|██▌       | 1/4 [00:04<00:12,  4.07s/it]
Loading checkpoint shards:  25%|██▌       | 1/4 [00:04<00:12,  4.10s/it]
Loading checkpoint shards:  25%|██▌       | 1/4 [00:03<00:11,  3.94s/it]
Loading checkpoint shards:  25%|██▌       | 1/4 [00:03<00:11,  3.82s/it]
Loading checkpoint shards:  25%|██▌       | 1/4 [00:04<00:12,  4.10s/it]
Loading checkpoint shards:  25%|██▌       | 1/4 [00:04<00:12,  4.02s/it]
Loading checkpoint shards:  25%|██▌       | 1/4 [00:04<00:12,  4.07s/it]
Loading checkpoint shards:  25%|██▌       | 1/4 [00:03<00:11,  3.91s/it]
Loading checkpoint shards:  50%|█████     | 2/4 [00:08<00:08,  4.02s/it]
Loading checkpoint shards:  50%|█████     | 2/4 [00:08<00:08,  4.09s/it]
Loading checkpoint shards:  50%|█████     | 2/4 [00:07<00:07,  3.91s/it]
Loading checkpoint shards:  50%|█████     | 2/4 [00:07<00:07,  3.96s/it]
Loading checkpoint shards:  50%|█████     | 2/4 [00:08<00:08,  4.11s/it]
Loading checkpoint shards:  50%|█████     | 2/4 [00:08<00:08,  4.04s/it]
Loading checkpoint shards:  50%|█████     | 2/4 [00:08<00:08,  4.08s/it]
Loading checkpoint shards:  50%|█████     | 2/4 [00:08<00:08,  4.02s/it]
Loading checkpoint shards:  75%|███████▌  | 3/4 [00:12<00:04,  4.06s/it]
Loading checkpoint shards:  75%|███████▌  | 3/4 [00:12<00:04,  4.05s/it]
Loading checkpoint shards:  75%|███████▌  | 3/4 [00:11<00:03,  3.92s/it]
Loading checkpoint shards:  75%|███████▌  | 3/4 [00:11<00:03,  3.96s/it]
Loading checkpoint shards:  75%|███████▌  | 3/4 [00:11<00:03,  3.92s/it]
Loading checkpoint shards:  75%|███████▌  | 3/4 [00:11<00:03,  3.85s/it]
Loading checkpoint shards:  75%|███████▌  | 3/4 [00:12<00:04,  4.03s/it]
Loading checkpoint shards:  75%|███████▌  | 3/4 [00:11<00:03,  4.00s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [00:15<00:00,  3.88s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [00:15<00:00,  3.94s/it]

Loading checkpoint shards: 100%|██████████| 4/4 [00:15<00:00,  3.87s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [00:15<00:00,  3.95s/it]

Loading checkpoint shards: 100%|██████████| 4/4 [00:15<00:00,  3.77s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [00:15<00:00,  3.82s/it]
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.

Loading checkpoint shards: 100%|██████████| 4/4 [00:15<00:00,  3.79s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [00:15<00:00,  3.84s/it]

Loading checkpoint shards: 100%|██████████| 4/4 [00:15<00:00,  3.73s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [00:15<00:00,  3.84s/it]
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.

Loading checkpoint shards: 100%|██████████| 4/4 [00:15<00:00,  3.64s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [00:15<00:00,  3.76s/it]
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.

Loading checkpoint shards: 100%|██████████| 4/4 [00:15<00:00,  3.75s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [00:15<00:00,  3.86s/it]
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.

Loading checkpoint shards: 100%|██████████| 4/4 [00:15<00:00,  3.77s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [00:15<00:00,  3.85s/it]
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
/work/.env/openmind_finetune/lib/python3.10/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: 
dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)
  warnings.warn(
/work/.env/openmind_finetune/lib/python3.10/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: 
dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)
  warnings.warn(
/work/.env/openmind_finetune/lib/python3.10/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: 
dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)
  warnings.warn(
/work/.env/openmind_finetune/lib/python3.10/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: 
dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)
  warnings.warn(
/work/.env/openmind_finetune/lib/python3.10/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: 
dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)
  warnings.warn(
/work/.env/openmind_finetune/lib/python3.10/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: 
dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)
  warnings.warn(
/work/.env/openmind_finetune/lib/python3.10/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: 
dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)
  warnings.warn(
Detected kernel version 4.19.90, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
/work/.env/openmind_finetune/lib/python3.10/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: 
dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)
  warnings.warn(
Warning: The torch.npu.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='npu') to create tensors.
Warning: The torch.npu.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='npu') to create tensors.
Warning: The torch.npu.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='npu') to create tensors.
Warning: The torch.npu.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='npu') to create tensors.
Warning: The torch.npu.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='npu') to create tensors.
Warning: The torch.npu.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='npu') to create tensors.
Warning: The torch.npu.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='npu') to create tensors.
Warning: The torch.npu.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='npu') to create tensors.

  0%|          | 0/200 [00:00<?, ?it/s]Warning: Device do not support double dtype now, dtype cast repalce with float.
Warning: Device do not support double dtype now, dtype cast repalce with float.
Warning: Device do not support double dtype now, dtype cast repalce with float.
Warning: Device do not support double dtype now, dtype cast repalce with float.
Warning: Device do not support double dtype now, dtype cast repalce with float.
Warning: Device do not support double dtype now, dtype cast repalce with float.
Warning: Device do not support double dtype now, dtype cast repalce with float.
Warning: Device do not support double dtype now, dtype cast repalce with float.

  0%|          | 1/200 [00:05<18:57,  5.71s/it]
                                               
{'loss': 2.2011, 'grad_norm': 7.67790802279145, 'learning_rate': 3.333333333333333e-07, 'epoch': 0.0}

  0%|          | 1/200 [00:06<18:57,  5.71s/it]
  1%|          | 2/200 [00:06<09:57,  3.02s/it]
                                               
{'loss': 1.8968, 'grad_norm': 7.43950260673686, 'learning_rate': 6.666666666666666e-07, 'epoch': 0.01}

  1%|          | 2/200 [00:06<09:57,  3.02s/it]
  2%|▏         | 3/200 [00:07<05:50,  1.78s/it]
                                               
{'loss': 1.1589, 'grad_norm': 4.465058409168915, 'learning_rate': 1e-06, 'epoch': 0.01}

  2%|▏         | 3/200 [00:07<05:50,  1.78s/it]
  2%|▏         | 4/200 [00:07<03:53,  1.19s/it]
                                               
{'loss': 1.4558, 'grad_norm': 5.347550852972048, 'learning_rate': 1.3333333333333332e-06, 'epoch': 0.02}

  2%|▏         | 4/200 [00:07<03:53,  1.19s/it]
  2%|▎         | 5/200 [00:07<02:49,  1.15it/s]
                                               
{'loss': 2.4939, 'grad_norm': 9.66472759749034, 'learning_rate': 1.6666666666666667e-06, 'epoch': 0.02}

  2%|▎         | 5/200 [00:07<02:49,  1.15it/s]
  3%|▎         | 6/200 [00:08<02:11,  1.47it/s]
                                               
{'loss': 0.617, 'grad_norm': 2.603687781489279, 'learning_rate': 2e-06, 'epoch': 0.02}

  3%|▎         | 6/200 [00:08<02:11,  1.47it/s]
  4%|▎         | 7/200 [00:08<01:46,  1.82it/s]
                                               
{'loss': 1.863, 'grad_norm': 6.920344129616276, 'learning_rate': 1.999868883665632e-06, 'epoch': 0.03}

  4%|▎         | 7/200 [00:08<01:46,  1.82it/s]
  4%|▍         | 8/200 [00:08<01:29,  2.14it/s]
                                               
{'loss': 1.4782, 'grad_norm': 5.810758268213481, 'learning_rate': 1.9994755690455148e-06, 'epoch': 0.03}

  4%|▍         | 8/200 [00:08<01:29,  2.14it/s]
  4%|▍         | 9/200 [00:08<01:18,  2.43it/s]
                                               
{'loss': 3.0435, 'grad_norm': 10.904239327102756, 'learning_rate': 1.9988201592795905e-06, 'epoch': 0.04}

  4%|▍         | 9/200 [00:08<01:18,  2.43it/s]
  5%|▌         | 10/200 [00:09<01:10,  2.69it/s]
                                                
{'loss': 2.1771, 'grad_norm': 8.688461579820874, 'learning_rate': 1.9979028262377116e-06, 'epoch': 0.04}

  5%|▌         | 10/200 [00:09<01:10,  2.69it/s]
  6%|▌         | 11/200 [00:09<01:06,  2.85it/s]
                                                
{'loss': 2.1271, 'grad_norm': 8.183348556887678, 'learning_rate': 1.9967238104745693e-06, 'epoch': 0.04}

  6%|▌         | 11/200 [00:09<01:06,  2.85it/s]
  6%|▌         | 12/200 [00:09<01:02,  3.03it/s]
                                                
{'loss': 1.5089, 'grad_norm': 5.765241243156861, 'learning_rate': 1.995283421166614e-06, 'epoch': 0.05}

  6%|▌         | 12/200 [00:09<01:02,  3.03it/s]
  6%|▋         | 13/200 [00:10<00:59,  3.12it/s]
                                                
{'loss': 1.2229, 'grad_norm': 4.604283925400153, 'learning_rate': 1.9935820360309776e-06, 'epoch': 0.05}

  6%|▋         | 13/200 [00:10<00:59,  3.12it/s]
  7%|▋         | 14/200 [00:10<00:57,  3.25it/s]
                                                
{'loss': 2.2334, 'grad_norm': 8.599964017570983, 'learning_rate': 1.991620101226425e-06, 'epoch': 0.06}

  7%|▋         | 14/200 [00:10<00:57,  3.25it/s]
  8%|▊         | 15/200 [00:10<00:55,  3.35it/s]
                                                
{'loss': 1.6903, 'grad_norm': 6.754284382036911, 'learning_rate': 1.9893981312363557e-06, 'epoch': 0.06}

  8%|▊         | 15/200 [00:10<00:55,  3.35it/s]
  8%|▊         | 16/200 [00:10<00:54,  3.35it/s]
                                                
{'loss': 1.8536, 'grad_norm': 6.1379074800490905, 'learning_rate': 1.9869167087338906e-06, 'epoch': 0.06}

  8%|▊         | 16/200 [00:10<00:54,  3.35it/s]
  8%|▊         | 17/200 [00:11<00:53,  3.41it/s]
                                                
{'loss': 1.2638, 'grad_norm': 4.929276777226938, 'learning_rate': 1.984176484429074e-06, 'epoch': 0.07}

  8%|▊         | 17/200 [00:11<00:53,  3.41it/s]
  9%|▉         | 18/200 [00:11<00:52,  3.46it/s]
                                                
{'loss': 1.55, 'grad_norm': 6.0314976142297345, 'learning_rate': 1.981178176898239e-06, 'epoch': 0.07}

  9%|▉         | 18/200 [00:11<00:52,  3.46it/s]
 10%|▉         | 19/200 [00:12<01:04,  2.82it/s]
                                                
{'loss': 1.366, 'grad_norm': 5.623749657584487, 'learning_rate': 1.9779225723955706e-06, 'epoch': 0.08}

 10%|▉         | 19/200 [00:12<01:04,  2.82it/s]
 10%|█         | 20/200 [00:12<01:00,  2.98it/s]
                                                
{'loss': 2.3874, 'grad_norm': 9.214879765587735, 'learning_rate': 1.9744105246469262e-06, 'epoch': 0.08}

 10%|█         | 20/200 [00:12<01:00,  2.98it/s]
 10%|█         | 21/200 [00:12<00:57,  3.12it/s]
                                                
{'loss': 1.4095, 'grad_norm': 5.156674084418661, 'learning_rate': 1.970642954625959e-06, 'epoch': 0.08}

 10%|█         | 21/200 [00:12<00:57,  3.12it/s]
 11%|█         | 22/200 [00:12<01:01,  2.91it/s]
                                                
{'loss': 1.7974, 'grad_norm': 7.5707176265436935, 'learning_rate': 1.966620850312611e-06, 'epoch': 0.09}

 11%|█         | 22/200 [00:12<01:01,  2.91it/s]
 12%|█▏        | 23/200 [00:13<00:57,  3.07it/s]
                                                
{'loss': 2.3355, 'grad_norm': 8.349223538234334, 'learning_rate': 1.96234526643403e-06, 'epoch': 0.09}

 12%|█▏        | 23/200 [00:13<00:57,  3.07it/s]
 12%|█▏        | 24/200 [00:13<00:56,  3.09it/s]
                                                
{'loss': 2.0493, 'grad_norm': 7.692046519027229, 'learning_rate': 1.957817324187987e-06, 'epoch': 0.1}

 12%|█▏        | 24/200 [00:13<00:56,  3.09it/s]
 12%|█▎        | 25/200 [00:13<00:54,  3.22it/s]
                                                
{'loss': 2.3026, 'grad_norm': 7.5514210658342575, 'learning_rate': 1.953038210948861e-06, 'epoch': 0.1}

 12%|█▎        | 25/200 [00:13<00:54,  3.22it/s]
 13%|█▎        | 26/200 [00:14<00:52,  3.30it/s]
                                                
{'loss': 2.0461, 'grad_norm': 7.8316924899462235, 'learning_rate': 1.9480091799562703e-06, 'epoch': 0.1}

 13%|█▎        | 26/200 [00:14<00:52,  3.30it/s]
 14%|█▎        | 27/200 [00:14<00:57,  3.00it/s]
                                                
{'loss': 1.8404, 'grad_norm': 6.738671580633, 'learning_rate': 1.9427315499864343e-06, 'epoch': 0.11}

 14%|█▎        | 27/200 [00:14<00:57,  3.00it/s]
 14%|█▍        | 28/200 [00:14<00:59,  2.88it/s]
                                                
{'loss': 2.0055, 'grad_norm': 8.644953548908923, 'learning_rate': 1.9372067050063438e-06, 'epoch': 0.11}

 14%|█▍        | 28/200 [00:14<00:59,  2.88it/s]
 14%|█▍        | 29/200 [00:15<00:57,  2.96it/s]
                                                
{'loss': 1.2171, 'grad_norm': 4.082900251401034, 'learning_rate': 1.9314360938108424e-06, 'epoch': 0.12}

 14%|█▍        | 29/200 [00:15<00:57,  2.96it/s]
 15%|█▌        | 30/200 [00:15<00:54,  3.14it/s]
                                                
{'loss': 1.7552, 'grad_norm': 6.404644723131878, 'learning_rate': 1.925421229642704e-06, 'epoch': 0.12}

 15%|█▌        | 30/200 [00:15<00:54,  3.14it/s]
 16%|█▌        | 31/200 [00:15<00:52,  3.20it/s]
                                                
{'loss': 1.6723, 'grad_norm': 6.138310819003332, 'learning_rate': 1.919163689795812e-06, 'epoch': 0.12}

 16%|█▌        | 31/200 [00:15<00:52,  3.20it/s]
 16%|█▌        | 32/200 [00:16<00:51,  3.28it/s]
                                                
{'loss': 2.5625, 'grad_norm': 8.010196386780112, 'learning_rate': 1.91266511520154e-06, 'epoch': 0.13}

 16%|█▌        | 32/200 [00:16<00:51,  3.28it/s]
 16%|█▋        | 33/200 [00:16<00:50,  3.34it/s]
                                                
{'loss': 1.78, 'grad_norm': 6.7715297243037265, 'learning_rate': 1.9059272099984466e-06, 'epoch': 0.13}

 16%|█▋        | 33/200 [00:16<00:50,  3.34it/s]
 17%|█▋        | 34/200 [00:16<00:48,  3.39it/s]
                                                
{'loss': 2.7854, 'grad_norm': 8.055428649370414, 'learning_rate': 1.8989517410853952e-06, 'epoch': 0.14}

 17%|█▋        | 34/200 [00:16<00:48,  3.39it/s]
 18%|█▊        | 35/200 [00:16<00:47,  3.44it/s]
                                                
{'loss': 1.405, 'grad_norm': 5.702053021578164, 'learning_rate': 1.8917405376582143e-06, 'epoch': 0.14}

 18%|█▊        | 35/200 [00:16<00:47,  3.44it/s]
 18%|█▊        | 36/200 [00:17<00:47,  3.46it/s]
                                                
{'loss': 1.7468, 'grad_norm': 6.601437105872703, 'learning_rate': 1.8842954907300234e-06, 'epoch': 0.14}

 18%|█▊        | 36/200 [00:17<00:47,  3.46it/s]
 18%|█▊        | 37/200 [00:17<00:48,  3.34it/s]
                                                
{'loss': 1.4806, 'grad_norm': 5.327431194518069, 'learning_rate': 1.8766185526353477e-06, 'epoch': 0.15}

 18%|█▊        | 37/200 [00:17<00:48,  3.34it/s]
 19%|█▉        | 38/200 [00:17<00:47,  3.43it/s]
                                                
{'loss': 1.928, 'grad_norm': 7.691998165945706, 'learning_rate': 1.868711736518151e-06, 'epoch': 0.15}

 19%|█▉        | 38/200 [00:17<00:47,  3.43it/s]
 20%|█▉        | 39/200 [00:18<00:47,  3.39it/s]
                                                
{'loss': 1.0388, 'grad_norm': 3.9581899650443058, 'learning_rate': 1.8605771158039252e-06, 'epoch': 0.16}

 20%|█▉        | 39/200 [00:18<00:47,  3.39it/s]
 20%|██        | 40/200 [00:18<00:46,  3.41it/s]
                                                
{'loss': 2.1808, 'grad_norm': 8.762012628124326, 'learning_rate': 1.8522168236559692e-06, 'epoch': 0.16}

 20%|██        | 40/200 [00:18<00:46,  3.41it/s]
 20%|██        | 41/200 [00:18<00:46,  3.45it/s]
                                                
{'loss': 1.8706, 'grad_norm': 8.278639126311244, 'learning_rate': 1.8436330524160044e-06, 'epoch': 0.16}

 20%|██        | 41/200 [00:18<00:46,  3.45it/s]
 21%|██        | 42/200 [00:19<00:45,  3.44it/s]
                                                
{'loss': 1.691, 'grad_norm': 5.974374727228588, 'learning_rate': 1.834828053029271e-06, 'epoch': 0.17}

 21%|██        | 42/200 [00:19<00:45,  3.44it/s]
 22%|██▏       | 43/200 [00:19<00:45,  3.48it/s]
                                                
{'loss': 1.3829, 'grad_norm': 5.172724443731404, 'learning_rate': 1.8258041344542563e-06, 'epoch': 0.17}

 22%|██▏       | 43/200 [00:19<00:45,  3.48it/s]
 22%|██▏       | 44/200 [00:19<00:48,  3.23it/s]
                                                
{'loss': 1.4197, 'grad_norm': 5.207175204897752, 'learning_rate': 1.8165636630572108e-06, 'epoch': 0.18}

 22%|██▏       | 44/200 [00:19<00:48,  3.23it/s]
 22%|██▎       | 45/200 [00:19<00:49,  3.15it/s]
                                                
{'loss': 3.2867, 'grad_norm': 11.10110547858544, 'learning_rate': 1.8071090619916092e-06, 'epoch': 0.18}

 22%|██▎       | 45/200 [00:19<00:49,  3.15it/s]
 23%|██▎       | 46/200 [00:20<00:47,  3.25it/s]
                                                
{'loss': 1.6501, 'grad_norm': 7.560553938739919, 'learning_rate': 1.7974428105627206e-06, 'epoch': 0.18}

 23%|██▎       | 46/200 [00:20<00:47,  3.25it/s]
 24%|██▎       | 47/200 [00:20<00:45,  3.36it/s]
                                                
{'loss': 0.9873, 'grad_norm': 4.831074724065232, 'learning_rate': 1.7875674435774543e-06, 'epoch': 0.19}

 24%|██▎       | 47/200 [00:20<00:45,  3.36it/s]
 24%|██▍       | 48/200 [00:20<00:45,  3.37it/s]
                                                
{'loss': 1.3742, 'grad_norm': 6.100680904220216, 'learning_rate': 1.7774855506796493e-06, 'epoch': 0.19}

 24%|██▍       | 48/200 [00:20<00:45,  3.37it/s]
 24%|██▍       | 49/200 [00:21<00:46,  3.27it/s]
                                                
{'loss': 1.3628, 'grad_norm': 5.585865793901646, 'learning_rate': 1.767199775670986e-06, 'epoch': 0.2}

 24%|██▍       | 49/200 [00:21<00:46,  3.27it/s]
 25%|██▌       | 50/200 [00:21<00:44,  3.36it/s]
                                                
{'loss': 1.5827, 'grad_norm': 6.363842643763285, 'learning_rate': 1.7567128158176952e-06, 'epoch': 0.2}

 25%|██▌       | 50/200 [00:21<00:44,  3.36it/s]
 26%|██▌       | 51/200 [00:21<00:43,  3.43it/s]
                                                
{'loss': 1.4833, 'grad_norm': 5.85653316501244, 'learning_rate': 1.746027421143246e-06, 'epoch': 0.2}

 26%|██▌       | 51/200 [00:21<00:43,  3.43it/s]
 26%|██▌       | 52/200 [00:22<00:45,  3.29it/s]
                                                
{'loss': 1.8759, 'grad_norm': 7.958668753327739, 'learning_rate': 1.7351463937072005e-06, 'epoch': 0.21}

 26%|██▌       | 52/200 [00:22<00:45,  3.29it/s]
 26%|██▋       | 53/200 [00:22<00:45,  3.25it/s]
                                                
{'loss': 1.5307, 'grad_norm': 6.32874134971032, 'learning_rate': 1.7240725868704217e-06, 'epoch': 0.21}

 26%|██▋       | 53/200 [00:22<00:45,  3.25it/s]
 27%|██▋       | 54/200 [00:22<00:44,  3.29it/s]
                                                
{'loss': 1.2589, 'grad_norm': 5.049425360589853, 'learning_rate': 1.7128089045468293e-06, 'epoch': 0.22}

 27%|██▋       | 54/200 [00:22<00:44,  3.29it/s]
 28%|██▊       | 55/200 [00:22<00:42,  3.41it/s]
                                                
{'loss': 2.4547, 'grad_norm': 8.258979765390924, 'learning_rate': 1.7013583004418993e-06, 'epoch': 0.22}

 28%|██▊       | 55/200 [00:22<00:42,  3.41it/s]
 28%|██▊       | 56/200 [00:23<00:42,  3.38it/s]
                                                
{'loss': 2.1404, 'grad_norm': 7.130428187285333, 'learning_rate': 1.6897237772781043e-06, 'epoch': 0.22}

 28%|██▊       | 56/200 [00:23<00:42,  3.38it/s]
 28%|██▊       | 57/200 [00:23<00:44,  3.23it/s]
                                                
{'loss': 1.8148, 'grad_norm': 7.130875958622185, 'learning_rate': 1.6779083860075032e-06, 'epoch': 0.23}

 28%|██▊       | 57/200 [00:23<00:44,  3.23it/s]
 29%|██▉       | 58/200 [00:23<00:42,  3.34it/s]
                                                
{'loss': 1.8199, 'grad_norm': 6.1082553471699645, 'learning_rate': 1.665915225011681e-06, 'epoch': 0.23}

 29%|██▉       | 58/200 [00:23<00:42,  3.34it/s]
 30%|██▉       | 59/200 [00:24<00:41,  3.42it/s]
                                                
{'loss': 1.6016, 'grad_norm': 6.90306881095568, 'learning_rate': 1.6537474392892526e-06, 'epoch': 0.24}

 30%|██▉       | 59/200 [00:24<00:41,  3.42it/s]
 30%|███       | 60/200 [00:24<00:40,  3.46it/s]
                                                
{'loss': 1.535, 'grad_norm': 5.814114910280103, 'learning_rate': 1.6414082196311398e-06, 'epoch': 0.24}

 30%|███       | 60/200 [00:24<00:40,  3.46it/s]
 30%|███       | 61/200 [00:24<00:39,  3.49it/s]
                                                
{'loss': 2.0494, 'grad_norm': 8.252193274981884, 'learning_rate': 1.6289008017838443e-06, 'epoch': 0.24}

 30%|███       | 61/200 [00:24<00:39,  3.49it/s]
 31%|███       | 62/200 [00:24<00:39,  3.50it/s]
                                                
{'loss': 1.2873, 'grad_norm': 6.0208213656437435, 'learning_rate': 1.6162284656009272e-06, 'epoch': 0.25}

 31%|███       | 62/200 [00:24<00:39,  3.50it/s]
 32%|███▏      | 63/200 [00:25<00:39,  3.50it/s]
                                                
{'loss': 1.7434, 'grad_norm': 7.082252090806594, 'learning_rate': 1.6033945341829246e-06, 'epoch': 0.25}

 32%|███▏      | 63/200 [00:25<00:39,  3.50it/s]
 32%|███▏      | 64/200 [00:25<00:39,  3.49it/s]
                                                
{'loss': 1.9454, 'grad_norm': 8.404507254295162, 'learning_rate': 1.5904023730059225e-06, 'epoch': 0.26}

 32%|███▏      | 64/200 [00:25<00:39,  3.49it/s]
 32%|███▎      | 65/200 [00:25<00:42,  3.16it/s]
                                                
{'loss': 1.4301, 'grad_norm': 6.132641443673367, 'learning_rate': 1.5772553890390194e-06, 'epoch': 0.26}

 32%|███▎      | 65/200 [00:25<00:42,  3.16it/s]
 33%|███▎      | 66/200 [00:26<00:40,  3.27it/s]
                                                
{'loss': 1.6567, 'grad_norm': 6.633961788036388, 'learning_rate': 1.5639570298509065e-06, 'epoch': 0.26}

 33%|███▎      | 66/200 [00:26<00:40,  3.27it/s]
 34%|███▎      | 67/200 [00:26<00:40,  3.32it/s]
                                                
{'loss': 1.5151, 'grad_norm': 6.060138989859557, 'learning_rate': 1.5505107827058035e-06, 'epoch': 0.27}

 34%|███▎      | 67/200 [00:26<00:40,  3.32it/s]
 34%|███▍      | 68/200 [00:26<00:38,  3.41it/s]
                                                
{'loss': 0.7413, 'grad_norm': 3.28486448754558, 'learning_rate': 1.5369201736489838e-06, 'epoch': 0.27}

 34%|███▍      | 68/200 [00:26<00:38,  3.41it/s]
 34%|███▍      | 69/200 [00:27<00:37,  3.47it/s]
                                                
{'loss': 1.236, 'grad_norm': 5.740732436817868, 'learning_rate': 1.52318876658213e-06, 'epoch': 0.28}

 34%|███▍      | 69/200 [00:27<00:37,  3.47it/s]
 35%|███▌      | 70/200 [00:27<00:36,  3.52it/s]
                                                
{'loss': 1.7903, 'grad_norm': 7.285987458864613, 'learning_rate': 1.509320162328763e-06, 'epoch': 0.28}

 35%|███▌      | 70/200 [00:27<00:36,  3.52it/s]
 36%|███▌      | 71/200 [00:27<00:36,  3.55it/s]
                                                
{'loss': 1.2586, 'grad_norm': 5.428647255905723, 'learning_rate': 1.4953179976899876e-06, 'epoch': 0.28}

 36%|███▌      | 71/200 [00:27<00:36,  3.55it/s]
 36%|███▌      | 72/200 [00:27<00:36,  3.51it/s]
                                                
{'loss': 1.1953, 'grad_norm': 5.255674655918799, 'learning_rate': 1.481185944490805e-06, 'epoch': 0.29}

 36%|███▌      | 72/200 [00:28<00:36,  3.51it/s]
 36%|███▋      | 73/200 [00:28<00:45,  2.81it/s]
                                                
{'loss': 0.6986, 'grad_norm': 3.5147146445035333, 'learning_rate': 1.4669277086172405e-06, 'epoch': 0.29}

 36%|███▋      | 73/200 [00:28<00:45,  2.81it/s]
 37%|███▋      | 74/200 [00:28<00:43,  2.86it/s]
                                                
{'loss': 0.9206, 'grad_norm': 3.9508690710945045, 'learning_rate': 1.452547029044539e-06, 'epoch': 0.3}

 37%|███▋      | 74/200 [00:28<00:43,  2.86it/s]
 38%|███▊      | 75/200 [00:29<00:48,  2.58it/s]
                                                
{'loss': 1.2911, 'grad_norm': 5.621165176372553, 'learning_rate': 1.4380476768566823e-06, 'epoch': 0.3}

 38%|███▊      | 75/200 [00:29<00:48,  2.58it/s]
 38%|███▊      | 76/200 [00:29<00:46,  2.66it/s]
                                                
{'loss': 0.9362, 'grad_norm': 3.643725863290086, 'learning_rate': 1.4234334542574904e-06, 'epoch': 0.3}

 38%|███▊      | 76/200 [00:29<00:46,  2.66it/s]
 38%|███▊      | 77/200 [00:29<00:43,  2.82it/s]
                                                
{'loss': 1.5545, 'grad_norm': 6.923366411791581, 'learning_rate': 1.4087081935735562e-06, 'epoch': 0.31}

 38%|███▊      | 77/200 [00:29<00:43,  2.82it/s]
 39%|███▉      | 78/200 [00:30<00:41,  2.97it/s]
                                                
{'loss': 1.636, 'grad_norm': 7.752310623764003, 'learning_rate': 1.3938757562492871e-06, 'epoch': 0.31}

 39%|███▉      | 78/200 [00:30<00:41,  2.97it/s]
 40%|███▉      | 79/200 [00:30<00:38,  3.13it/s]
                                                
{'loss': 0.8901, 'grad_norm': 3.8655214362121857, 'learning_rate': 1.3789400318343068e-06, 'epoch': 0.32}

 40%|███▉      | 79/200 [00:30<00:38,  3.13it/s]
 40%|████      | 80/200 [00:30<00:36,  3.25it/s]
                                                
{'loss': 1.2704, 'grad_norm': 6.409793822592466, 'learning_rate': 1.3639049369634876e-06, 'epoch': 0.32}

 40%|████      | 80/200 [00:30<00:36,  3.25it/s]
 40%|████      | 81/200 [00:31<00:35,  3.33it/s]
                                                
{'loss': 1.1389, 'grad_norm': 4.654827130935851, 'learning_rate': 1.3487744143298821e-06, 'epoch': 0.32}

 40%|████      | 81/200 [00:31<00:35,  3.33it/s]
 41%|████      | 82/200 [00:31<00:34,  3.38it/s]
                                                
{'loss': 1.1212, 'grad_norm': 5.343932388494706, 'learning_rate': 1.3335524316508207e-06, 'epoch': 0.33}

 41%|████      | 82/200 [00:31<00:34,  3.38it/s]
 42%|████▏     | 83/200 [00:31<00:33,  3.46it/s]
                                                
{'loss': 1.2011, 'grad_norm': 5.729597299748487, 'learning_rate': 1.318242980627444e-06, 'epoch': 0.33}

 42%|████▏     | 83/200 [00:31<00:33,  3.46it/s]
 42%|████▏     | 84/200 [00:31<00:33,  3.49it/s]
                                                
{'loss': 1.7843, 'grad_norm': 7.463006145239126, 'learning_rate': 1.3028500758979505e-06, 'epoch': 0.34}

 42%|████▏     | 84/200 [00:31<00:33,  3.49it/s]
 42%|████▎     | 85/200 [00:32<00:32,  3.54it/s]
                                                
{'loss': 1.9348, 'grad_norm': 9.216006113103322, 'learning_rate': 1.2873777539848283e-06, 'epoch': 0.34}

 42%|████▎     | 85/200 [00:32<00:32,  3.54it/s]
 43%|████▎     | 86/200 [00:32<00:31,  3.58it/s]
                                                
{'loss': 1.4269, 'grad_norm': 6.168719834830786, 'learning_rate': 1.2718300722363428e-06, 'epoch': 0.34}

 43%|████▎     | 86/200 [00:32<00:31,  3.58it/s]
 44%|████▎     | 87/200 [00:32<00:31,  3.54it/s]
                                                
{'loss': 1.4738, 'grad_norm': 6.465399570139691, 'learning_rate': 1.2562111077625722e-06, 'epoch': 0.35}

 44%|████▎     | 87/200 [00:32<00:31,  3.54it/s]
 44%|████▍     | 88/200 [00:32<00:31,  3.54it/s]
                                                
{'loss': 1.1384, 'grad_norm': 6.046842195485953, 'learning_rate': 1.2405249563662536e-06, 'epoch': 0.35}

 44%|████▍     | 88/200 [00:32<00:31,  3.54it/s]
 44%|████▍     | 89/200 [00:33<00:31,  3.48it/s]
                                                
{'loss': 1.5532, 'grad_norm': 8.391485585667931, 'learning_rate': 1.2247757314687295e-06, 'epoch': 0.36}

 44%|████▍     | 89/200 [00:33<00:31,  3.48it/s]
 45%|████▌     | 90/200 [00:33<00:31,  3.47it/s]
                                                
{'loss': 1.1321, 'grad_norm': 5.5752682676902525, 'learning_rate': 1.2089675630312752e-06, 'epoch': 0.36}

 45%|████▌     | 90/200 [00:33<00:31,  3.47it/s]
 46%|████▌     | 91/200 [00:33<00:30,  3.52it/s]
                                                
{'loss': 1.0438, 'grad_norm': 5.2832163022594445, 'learning_rate': 1.193104596472088e-06, 'epoch': 0.36}

 46%|████▌     | 91/200 [00:33<00:30,  3.52it/s]
 46%|████▌     | 92/200 [00:34<00:31,  3.47it/s]
                                                
{'loss': 1.5195, 'grad_norm': 7.045752459181663, 'learning_rate': 1.177190991579223e-06, 'epoch': 0.37}

 46%|████▌     | 92/200 [00:34<00:31,  3.47it/s]
 46%|████▋     | 93/200 [00:34<00:30,  3.54it/s]
                                                
{'loss': 1.07, 'grad_norm': 5.177034599131107, 'learning_rate': 1.1612309214197597e-06, 'epoch': 0.37}

 46%|████▋     | 93/200 [00:34<00:30,  3.54it/s]
 47%|████▋     | 94/200 [00:34<00:29,  3.54it/s]
                                                
{'loss': 1.1109, 'grad_norm': 4.78452423281557, 'learning_rate': 1.1452285712454903e-06, 'epoch': 0.38}

 47%|████▋     | 94/200 [00:34<00:29,  3.54it/s]
 48%|████▊     | 95/200 [00:34<00:29,  3.54it/s]
                                                
{'loss': 1.3003, 'grad_norm': 7.135347047637864, 'learning_rate': 1.1291881373954064e-06, 'epoch': 0.38}

 48%|████▊     | 95/200 [00:34<00:29,  3.54it/s]
 48%|████▊     | 96/200 [00:35<00:29,  3.52it/s]
                                                
{'loss': 1.5018, 'grad_norm': 7.945865338052173, 'learning_rate': 1.1131138261952845e-06, 'epoch': 0.38}

 48%|████▊     | 96/200 [00:35<00:29,  3.52it/s]
 48%|████▊     | 97/200 [00:35<00:29,  3.53it/s]
                                                
{'loss': 1.4737, 'grad_norm': 8.847180674994497, 'learning_rate': 1.0970098528546482e-06, 'epoch': 0.39}

 48%|████▊     | 97/200 [00:35<00:29,  3.53it/s]
 49%|████▉     | 98/200 [00:35<00:29,  3.51it/s]
                                                
{'loss': 1.5301, 'grad_norm': 7.952086015447161, 'learning_rate': 1.0808804403614043e-06, 'epoch': 0.39}

 49%|████▉     | 98/200 [00:35<00:29,  3.51it/s]
 50%|████▉     | 99/200 [00:36<00:28,  3.50it/s]
                                                
{'loss': 1.2039, 'grad_norm': 6.196765474322068, 'learning_rate': 1.0647298183744357e-06, 'epoch': 0.4}

 50%|████▉     | 99/200 [00:36<00:28,  3.50it/s]
 50%|█████     | 100/200 [00:36<00:28,  3.51it/s]
                                                 
{'loss': 0.1951, 'grad_norm': 1.6876537818067734, 'learning_rate': 1.0485622221144483e-06, 'epoch': 0.4}

 50%|█████     | 100/200 [00:36<00:28,  3.51it/s]
 50%|█████     | 101/200 [00:36<00:29,  3.37it/s]
                                                 
{'loss': 1.5009, 'grad_norm': 7.475107974290065, 'learning_rate': 1.032381891253356e-06, 'epoch': 0.4}

 50%|█████     | 101/200 [00:36<00:29,  3.37it/s]
 51%|█████     | 102/200 [00:37<00:28,  3.41it/s]
                                                 
{'loss': 0.5883, 'grad_norm': 3.7070886187440517, 'learning_rate': 1.0161930688025016e-06, 'epoch': 0.41}

 51%|█████     | 102/200 [00:37<00:28,  3.41it/s]
 52%|█████▏    | 103/200 [00:37<00:28,  3.44it/s]
                                                 
{'loss': 1.646, 'grad_norm': 7.9881267653919155, 'learning_rate': 1e-06, 'epoch': 0.41}

 52%|█████▏    | 103/200 [00:37<00:28,  3.44it/s]
 52%|█████▏    | 104/200 [00:37<00:27,  3.45it/s]
                                                 
{'loss': 1.0587, 'grad_norm': 5.516662500078332, 'learning_rate': 9.838069311974985e-07, 'epoch': 0.42}

 52%|█████▏    | 104/200 [00:37<00:27,  3.45it/s]
 52%|█████▎    | 105/200 [00:37<00:26,  3.52it/s]
                                                 
{'loss': 1.5841, 'grad_norm': 7.698802547730739, 'learning_rate': 9.676181087466442e-07, 'epoch': 0.42}

 52%|█████▎    | 105/200 [00:37<00:26,  3.52it/s]
 53%|█████▎    | 106/200 [00:38<00:27,  3.42it/s]
                                                 
{'loss': 0.9681, 'grad_norm': 6.203687666349838, 'learning_rate': 9.51437777885552e-07, 'epoch': 0.42}

 53%|█████▎    | 106/200 [00:38<00:27,  3.42it/s]
 54%|█████▎    | 107/200 [00:38<00:27,  3.40it/s]
                                                 
{'loss': 1.3483, 'grad_norm': 7.744866424452858, 'learning_rate': 9.352701816255642e-07, 'epoch': 0.43}

 54%|█████▎    | 107/200 [00:38<00:27,  3.40it/s]
 54%|█████▍    | 108/200 [00:38<00:26,  3.45it/s]
                                                 
{'loss': 1.0409, 'grad_norm': 6.064807256165967, 'learning_rate': 9.191195596385958e-07, 'epoch': 0.43}

 54%|█████▍    | 108/200 [00:38<00:26,  3.45it/s]
 55%|█████▍    | 109/200 [00:39<00:26,  3.47it/s]
                                                 
{'loss': 1.0128, 'grad_norm': 5.776357529181486, 'learning_rate': 9.029901471453519e-07, 'epoch': 0.44}

 55%|█████▍    | 109/200 [00:39<00:26,  3.47it/s]
 55%|█████▌    | 110/200 [00:39<00:26,  3.45it/s]
                                                 
{'loss': 0.4103, 'grad_norm': 2.334817369004789, 'learning_rate': 8.868861738047158e-07, 'epoch': 0.44}

 55%|█████▌    | 110/200 [00:39<00:26,  3.45it/s]
 56%|█████▌    | 111/200 [00:39<00:25,  3.50it/s]
                                                 
{'loss': 0.9934, 'grad_norm': 6.025143076357288, 'learning_rate': 8.708118626045938e-07, 'epoch': 0.44}

 56%|█████▌    | 111/200 [00:39<00:25,  3.50it/s]
 56%|█████▌    | 112/200 [00:39<00:24,  3.55it/s]
                                                 
{'loss': 1.0099, 'grad_norm': 5.847263524304019, 'learning_rate': 8.547714287545099e-07, 'epoch': 0.45}

 56%|█████▌    | 112/200 [00:39<00:24,  3.55it/s]
 56%|█████▋    | 113/200 [00:40<00:24,  3.55it/s]
                                                 
{'loss': 0.9419, 'grad_norm': 5.428203132870856, 'learning_rate': 8.387690785802402e-07, 'epoch': 0.45}

 56%|█████▋    | 113/200 [00:40<00:24,  3.55it/s]
 57%|█████▋    | 114/200 [00:40<00:24,  3.44it/s]
                                                 
{'loss': 1.2886, 'grad_norm': 7.289420982777724, 'learning_rate': 8.228090084207773e-07, 'epoch': 0.46}

 57%|█████▋    | 114/200 [00:40<00:24,  3.44it/s]
 57%|█████▊    | 115/200 [00:40<00:24,  3.50it/s]
                                                 
{'loss': 1.0245, 'grad_norm': 6.239110386352043, 'learning_rate': 8.068954035279121e-07, 'epoch': 0.46}

 57%|█████▊    | 115/200 [00:40<00:24,  3.50it/s]
 58%|█████▊    | 116/200 [00:41<00:24,  3.42it/s]
                                                 
{'loss': 1.5449, 'grad_norm': 8.183218032843001, 'learning_rate': 7.910324369687249e-07, 'epoch': 0.46}

 58%|█████▊    | 116/200 [00:41<00:24,  3.42it/s]
 58%|█████▊    | 117/200 [00:41<00:24,  3.45it/s]
                                                 
{'loss': 1.2832, 'grad_norm': 7.100937483239036, 'learning_rate': 7.752242685312709e-07, 'epoch': 0.47}

 58%|█████▊    | 117/200 [00:41<00:24,  3.45it/s]
 59%|█████▉    | 118/200 [00:41<00:23,  3.46it/s]
                                                 
{'loss': 1.3993, 'grad_norm': 8.000267501173447, 'learning_rate': 7.594750436337465e-07, 'epoch': 0.47}

 59%|█████▉    | 118/200 [00:41<00:23,  3.46it/s]
 60%|█████▉    | 119/200 [00:41<00:22,  3.53it/s]
                                                 
{'loss': 1.2969, 'grad_norm': 7.4266745377686645, 'learning_rate': 7.437888922374276e-07, 'epoch': 0.48}

 60%|█████▉    | 119/200 [00:41<00:22,  3.53it/s]
 60%|██████    | 120/200 [00:42<00:22,  3.50it/s]
                                                 
{'loss': 1.0263, 'grad_norm': 5.610038696808383, 'learning_rate': 7.28169927763657e-07, 'epoch': 0.48}

 60%|██████    | 120/200 [00:42<00:22,  3.50it/s]
 60%|██████    | 121/200 [00:42<00:22,  3.52it/s]
                                                 
{'loss': 1.0816, 'grad_norm': 5.414019872104009, 'learning_rate': 7.126222460151718e-07, 'epoch': 0.48}

 60%|██████    | 121/200 [00:42<00:22,  3.52it/s]
 61%|██████    | 122/200 [00:42<00:23,  3.30it/s]
                                                 
{'loss': 1.522, 'grad_norm': 7.961988984242887, 'learning_rate': 6.971499241020494e-07, 'epoch': 0.49}

 61%|██████    | 122/200 [00:42<00:23,  3.30it/s]
 62%|██████▏   | 123/200 [00:43<00:22,  3.38it/s]
                                                 
{'loss': 1.1748, 'grad_norm': 7.563280806153793, 'learning_rate': 6.817570193725563e-07, 'epoch': 0.49}

 62%|██████▏   | 123/200 [00:43<00:22,  3.38it/s]
 62%|██████▏   | 124/200 [00:43<00:22,  3.39it/s]
                                                 
{'loss': 0.8933, 'grad_norm': 4.993235017006369, 'learning_rate': 6.664475683491795e-07, 'epoch': 0.5}

 62%|██████▏   | 124/200 [00:43<00:22,  3.39it/s]
 62%|██████▎   | 125/200 [00:43<00:22,  3.38it/s]
                                                 
{'loss': 1.5968, 'grad_norm': 9.597452350169265, 'learning_rate': 6.512255856701177e-07, 'epoch': 0.5}

 62%|██████▎   | 125/200 [00:43<00:22,  3.38it/s]
 63%|██████▎   | 126/200 [00:43<00:21,  3.41it/s]
                                                 
{'loss': 1.6388, 'grad_norm': 9.087942464726957, 'learning_rate': 6.360950630365125e-07, 'epoch': 0.5}

 63%|██████▎   | 126/200 [00:43<00:21,  3.41it/s]
 64%|██████▎   | 127/200 [00:44<00:21,  3.39it/s]
                                                 
{'loss': 0.9107, 'grad_norm': 5.461142693022204, 'learning_rate': 6.210599681656932e-07, 'epoch': 0.51}

 64%|██████▎   | 127/200 [00:44<00:21,  3.39it/s]
 64%|██████▍   | 128/200 [00:44<00:21,  3.38it/s]
                                                 
{'loss': 0.5086, 'grad_norm': 3.677194321698108, 'learning_rate': 6.06124243750713e-07, 'epoch': 0.51}

 64%|██████▍   | 128/200 [00:44<00:21,  3.38it/s]
 64%|██████▍   | 129/200 [00:44<00:21,  3.35it/s]
                                                 
{'loss': 1.4975, 'grad_norm': 7.913011396373119, 'learning_rate': 5.91291806426444e-07, 'epoch': 0.52}

 64%|██████▍   | 129/200 [00:44<00:21,  3.35it/s]
 65%|██████▌   | 130/200 [00:45<00:21,  3.31it/s]
                                                 
{'loss': 1.5139, 'grad_norm': 8.200680439327504, 'learning_rate': 5.765665457425101e-07, 'epoch': 0.52}

 65%|██████▌   | 130/200 [00:45<00:21,  3.31it/s]
 66%|██████▌   | 131/200 [00:45<00:20,  3.33it/s]
                                                 
{'loss': 1.1673, 'grad_norm': 5.7697467905744135, 'learning_rate': 5.619523231433177e-07, 'epoch': 0.52}

 66%|██████▌   | 131/200 [00:45<00:20,  3.33it/s]
 66%|██████▌   | 132/200 [00:45<00:20,  3.39it/s]
                                                 
{'loss': 1.3736, 'grad_norm': 7.625444743209296, 'learning_rate': 5.474529709554611e-07, 'epoch': 0.53}

 66%|██████▌   | 132/200 [00:45<00:20,  3.39it/s]
 66%|██████▋   | 133/200 [00:46<00:19,  3.37it/s]
                                                 
{'loss': 1.0598, 'grad_norm': 5.941718600537938, 'learning_rate': 5.330722913827594e-07, 'epoch': 0.53}

 66%|██████▋   | 133/200 [00:46<00:19,  3.37it/s]
 67%|██████▋   | 134/200 [00:46<00:19,  3.44it/s]
                                                 
{'loss': 1.2807, 'grad_norm': 7.549410502680874, 'learning_rate': 5.188140555091949e-07, 'epoch': 0.54}

 67%|██████▋   | 134/200 [00:46<00:19,  3.44it/s]
 68%|██████▊   | 135/200 [00:46<00:21,  3.07it/s]
                                                 
{'loss': 1.0325, 'grad_norm': 5.4887330218864605, 'learning_rate': 5.046820023100128e-07, 'epoch': 0.54}

 68%|██████▊   | 135/200 [00:46<00:21,  3.07it/s]
 68%|██████▊   | 136/200 [00:47<00:19,  3.20it/s]
                                                 
{'loss': 1.4343, 'grad_norm': 9.063416743772134, 'learning_rate': 4.906798376712373e-07, 'epoch': 0.54}

 68%|██████▊   | 136/200 [00:47<00:19,  3.20it/s]
 68%|██████▊   | 137/200 [00:47<00:19,  3.29it/s]
                                                 
{'loss': 0.9579, 'grad_norm': 5.097416406594305, 'learning_rate': 4.768112334178699e-07, 'epoch': 0.55}

 68%|██████▊   | 137/200 [00:47<00:19,  3.29it/s]
 69%|██████▉   | 138/200 [00:47<00:18,  3.41it/s]
                                                 
{'loss': 0.6494, 'grad_norm': 5.358954321363173, 'learning_rate': 4.6307982635101616e-07, 'epoch': 0.55}

 69%|██████▉   | 138/200 [00:47<00:18,  3.41it/s]
 70%|██████▉   | 139/200 [00:47<00:17,  3.43it/s]
                                                 
{'loss': 1.1113, 'grad_norm': 7.038892602087398, 'learning_rate': 4.494892172941964e-07, 'epoch': 0.56}

 70%|██████▉   | 139/200 [00:47<00:17,  3.43it/s]
 70%|███████   | 140/200 [00:48<00:17,  3.50it/s]
                                                 
{'loss': 0.5604, 'grad_norm': 3.6413044438742714, 'learning_rate': 4.360429701490934e-07, 'epoch': 0.56}

 70%|███████   | 140/200 [00:48<00:17,  3.50it/s]
 70%|███████   | 141/200 [00:48<00:17,  3.36it/s]
                                                 
{'loss': 1.1283, 'grad_norm': 6.80438392916784, 'learning_rate': 4.227446109609808e-07, 'epoch': 0.56}

 70%|███████   | 141/200 [00:48<00:17,  3.36it/s]
 71%|███████   | 142/200 [00:48<00:16,  3.41it/s]
                                                 
{'loss': 0.5565, 'grad_norm': 4.05867152648949, 'learning_rate': 4.0959762699407763e-07, 'epoch': 0.57}

 71%|███████   | 142/200 [00:48<00:16,  3.41it/s]
 72%|███████▏  | 143/200 [00:49<00:16,  3.42it/s]
                                                 
{'loss': 1.1787, 'grad_norm': 7.540164467715231, 'learning_rate': 3.966054658170753e-07, 'epoch': 0.57}

 72%|███████▏  | 143/200 [00:49<00:16,  3.42it/s]
 72%|███████▏  | 144/200 [00:49<00:16,  3.46it/s]
                                                 
{'loss': 0.7817, 'grad_norm': 5.176879674128074, 'learning_rate': 3.837715343990726e-07, 'epoch': 0.58}

 72%|███████▏  | 144/200 [00:49<00:16,  3.46it/s]
 72%|███████▎  | 145/200 [00:49<00:15,  3.52it/s]
                                                 
{'loss': 0.9594, 'grad_norm': 5.499109889742864, 'learning_rate': 3.7109919821615543e-07, 'epoch': 0.58}

 72%|███████▎  | 145/200 [00:49<00:15,  3.52it/s]
 73%|███████▎  | 146/200 [00:49<00:15,  3.54it/s]
                                                 
{'loss': 0.949, 'grad_norm': 6.410275864400443, 'learning_rate': 3.585917803688603e-07, 'epoch': 0.58}

 73%|███████▎  | 146/200 [00:49<00:15,  3.54it/s]
 74%|███████▎  | 147/200 [00:50<00:14,  3.58it/s]
                                                 
{'loss': 0.8758, 'grad_norm': 5.146890734965227, 'learning_rate': 3.462525607107477e-07, 'epoch': 0.59}

 74%|███████▎  | 147/200 [00:50<00:14,  3.58it/s]
 74%|███████▍  | 148/200 [00:50<00:14,  3.56it/s]
                                                 
{'loss': 0.7293, 'grad_norm': 5.42100513527111, 'learning_rate': 3.340847749883191e-07, 'epoch': 0.59}

 74%|███████▍  | 148/200 [00:50<00:14,  3.56it/s]
 74%|███████▍  | 149/200 [00:50<00:14,  3.57it/s]
                                                 
{'loss': 1.2029, 'grad_norm': 8.673194578655476, 'learning_rate': 3.2209161399249674e-07, 'epoch': 0.6}

 74%|███████▍  | 149/200 [00:50<00:14,  3.57it/s]
 75%|███████▌  | 150/200 [00:51<00:15,  3.18it/s]
                                                 
{'loss': 0.7223, 'grad_norm': 4.8025834601645085, 'learning_rate': 3.102762227218957e-07, 'epoch': 0.6}

 75%|███████▌  | 150/200 [00:51<00:15,  3.18it/s]
 76%|███████▌  | 151/200 [00:51<00:14,  3.28it/s]
                                                 
{'loss': 0.7448, 'grad_norm': 5.254000819606594, 'learning_rate': 2.986416995581008e-07, 'epoch': 0.6}

 76%|███████▌  | 151/200 [00:51<00:14,  3.28it/s]
 76%|███████▌  | 152/200 [00:51<00:14,  3.29it/s]
                                                 
{'loss': 1.0943, 'grad_norm': 5.853444589992736, 'learning_rate': 2.87191095453171e-07, 'epoch': 0.61}

 76%|███████▌  | 152/200 [00:51<00:14,  3.29it/s]
 76%|███████▋  | 153/200 [00:51<00:14,  3.28it/s]
                                                 
{'loss': 1.4791, 'grad_norm': 10.657352513530565, 'learning_rate': 2.7592741312957867e-07, 'epoch': 0.61}

 76%|███████▋  | 153/200 [00:51<00:14,  3.28it/s]
 77%|███████▋  | 154/200 [00:52<00:13,  3.31it/s]
                                                 
{'loss': 0.9314, 'grad_norm': 5.4447975736179375, 'learning_rate': 2.6485360629279986e-07, 'epoch': 0.62}

 77%|███████▋  | 154/200 [00:52<00:13,  3.31it/s]
 78%|███████▊  | 155/200 [00:52<00:13,  3.30it/s]
                                                 
{'loss': 0.9098, 'grad_norm': 6.452075642018778, 'learning_rate': 2.5397257885675395e-07, 'epoch': 0.62}

 78%|███████▊  | 155/200 [00:52<00:13,  3.30it/s]
 78%|███████▊  | 156/200 [00:52<00:12,  3.39it/s]
                                                 
{'loss': 0.7122, 'grad_norm': 4.393402415780656, 'learning_rate': 2.4328718418230463e-07, 'epoch': 0.62}

 78%|███████▊  | 156/200 [00:52<00:12,  3.39it/s]
 78%|███████▊  | 157/200 [00:53<00:12,  3.32it/s]
                                                 
{'loss': 1.2563, 'grad_norm': 10.022852915532894, 'learning_rate': 2.3280022432901381e-07, 'epoch': 0.63}

 78%|███████▊  | 157/200 [00:53<00:12,  3.32it/s]
 79%|███████▉  | 158/200 [00:53<00:12,  3.38it/s]
                                                 
{'loss': 1.5727, 'grad_norm': 9.883733436586997, 'learning_rate': 2.225144493203509e-07, 'epoch': 0.63}

 79%|███████▉  | 158/200 [00:53<00:12,  3.38it/s]
 80%|███████▉  | 159/200 [00:53<00:12,  3.38it/s]
                                                 
{'loss': 0.7925, 'grad_norm': 4.380917933528043, 'learning_rate': 2.1243255642254576e-07, 'epoch': 0.64}

 80%|███████▉  | 159/200 [00:53<00:12,  3.38it/s]
 80%|████████  | 160/200 [00:54<00:11,  3.40it/s]
                                                 
{'loss': 1.5696, 'grad_norm': 12.693706629203357, 'learning_rate': 2.0255718943727939e-07, 'epoch': 0.64}

 80%|████████  | 160/200 [00:54<00:11,  3.40it/s]
 80%|████████  | 161/200 [00:54<00:11,  3.38it/s]
                                                 
{'loss': 1.3235, 'grad_norm': 6.957761303199106, 'learning_rate': 1.9289093800839062e-07, 'epoch': 0.64}

 80%|████████  | 161/200 [00:54<00:11,  3.38it/s]
 81%|████████  | 162/200 [00:54<00:12,  3.05it/s]
                                                 
{'loss': 1.5408, 'grad_norm': 9.263022251824346, 'learning_rate': 1.8343633694278894e-07, 'epoch': 0.65}

 81%|████████  | 162/200 [00:54<00:12,  3.05it/s]
 82%|████████▏ | 163/200 [00:55<00:11,  3.17it/s]
                                                 
{'loss': 1.48, 'grad_norm': 8.702298301456866, 'learning_rate': 1.741958655457436e-07, 'epoch': 0.65}

 82%|████████▏ | 163/200 [00:55<00:11,  3.17it/s]
 82%|████████▏ | 164/200 [00:55<00:10,  3.30it/s]
                                                 
{'loss': 0.8879, 'grad_norm': 4.990044027680854, 'learning_rate': 1.6517194697072901e-07, 'epoch': 0.66}

 82%|████████▏ | 164/200 [00:55<00:10,  3.30it/s]
 82%|████████▎ | 165/200 [00:55<00:10,  3.38it/s]
                                                 
{'loss': 0.9245, 'grad_norm': 5.484957324464457, 'learning_rate': 1.563669475839956e-07, 'epoch': 0.66}

 82%|████████▎ | 165/200 [00:55<00:10,  3.38it/s]
 83%|████████▎ | 166/200 [00:55<00:09,  3.49it/s]
                                                 
{'loss': 0.298, 'grad_norm': 2.6178797475358935, 'learning_rate': 1.4778317634403082e-07, 'epoch': 0.66}

 83%|████████▎ | 166/200 [00:55<00:09,  3.49it/s]
 84%|████████▎ | 167/200 [00:56<00:09,  3.48it/s]
                                                 
{'loss': 1.1968, 'grad_norm': 7.773248564757962, 'learning_rate': 1.3942288419607473e-07, 'epoch': 0.67}

 84%|████████▎ | 167/200 [00:56<00:09,  3.48it/s]
 84%|████████▍ | 168/200 [00:56<00:09,  3.55it/s]
                                                 
{'loss': 1.0599, 'grad_norm': 7.894116405401018, 'learning_rate': 1.3128826348184886e-07, 'epoch': 0.67}

 84%|████████▍ | 168/200 [00:56<00:09,  3.55it/s]
 84%|████████▍ | 169/200 [00:56<00:08,  3.55it/s]
                                                 
{'loss': 1.8071, 'grad_norm': 12.341338025821111, 'learning_rate': 1.233814473646524e-07, 'epoch': 0.68}

 84%|████████▍ | 169/200 [00:56<00:08,  3.55it/s]
 85%|████████▌ | 170/200 [00:56<00:08,  3.60it/s]
                                                 
{'loss': 1.107, 'grad_norm': 6.527829967677931, 'learning_rate': 1.1570450926997655e-07, 'epoch': 0.68}

 85%|████████▌ | 170/200 [00:56<00:08,  3.60it/s]
 86%|████████▌ | 171/200 [00:57<00:08,  3.57it/s]
                                                 
{'loss': 0.6412, 'grad_norm': 4.408711712949204, 'learning_rate': 1.0825946234178573e-07, 'epoch': 0.68}

 86%|████████▌ | 171/200 [00:57<00:08,  3.57it/s]
 86%|████████▌ | 172/200 [00:57<00:08,  3.47it/s]
                                                 
{'loss': 1.2467, 'grad_norm': 9.635813398012054, 'learning_rate': 1.0104825891460478e-07, 'epoch': 0.69}

 86%|████████▌ | 172/200 [00:57<00:08,  3.47it/s]
 86%|████████▋ | 173/200 [00:57<00:07,  3.46it/s]
                                                 
{'loss': 0.8677, 'grad_norm': 6.3681379299274035, 'learning_rate': 9.40727900015531e-08, 'epoch': 0.69}

 86%|████████▋ | 173/200 [00:57<00:07,  3.46it/s]
 87%|████████▋ | 174/200 [00:58<00:07,  3.53it/s]
                                                 
{'loss': 1.124, 'grad_norm': 7.069129465510339, 'learning_rate': 8.733488479845996e-08, 'epoch': 0.7}

 87%|████████▋ | 174/200 [00:58<00:07,  3.53it/s]
 88%|████████▊ | 175/200 [00:58<00:06,  3.60it/s]
                                                 
{'loss': 1.1815, 'grad_norm': 5.896216533954906, 'learning_rate': 8.08363102041879e-08, 'epoch': 0.7}

 88%|████████▊ | 175/200 [00:58<00:06,  3.60it/s]
 88%|████████▊ | 176/200 [00:58<00:06,  3.58it/s]
                                                 
{'loss': 1.0588, 'grad_norm': 6.167430040003684, 'learning_rate': 7.457877035729587e-08, 'epoch': 0.7}

 88%|████████▊ | 176/200 [00:58<00:06,  3.58it/s]
 88%|████████▊ | 177/200 [00:58<00:06,  3.54it/s]
                                                 
{'loss': 0.8886, 'grad_norm': 6.077095631022582, 'learning_rate': 6.856390618915775e-08, 'epoch': 0.71}

 88%|████████▊ | 177/200 [00:58<00:06,  3.54it/s]
 89%|████████▉ | 178/200 [00:59<00:06,  3.54it/s]
                                                 
{'loss': 1.057, 'grad_norm': 6.356558361094315, 'learning_rate': 6.279329499365649e-08, 'epoch': 0.71}

 89%|████████▉ | 178/200 [00:59<00:06,  3.54it/s]
 90%|████████▉ | 179/200 [00:59<00:06,  3.49it/s]
                                                 
{'loss': 1.088, 'grad_norm': 6.208938296069973, 'learning_rate': 5.726845001356573e-08, 'epoch': 0.72}

 90%|████████▉ | 179/200 [00:59<00:06,  3.49it/s]
 90%|█████████ | 180/200 [00:59<00:05,  3.50it/s]
                                                 
{'loss': 0.9133, 'grad_norm': 5.316637828752681, 'learning_rate': 5.1990820043729566e-08, 'epoch': 0.72}

 90%|█████████ | 180/200 [00:59<00:05,  3.50it/s]
 90%|█████████ | 181/200 [01:00<00:05,  3.51it/s]
                                                 
{'loss': 0.7616, 'grad_norm': 5.310200990368017, 'learning_rate': 4.696178905113912e-08, 'epoch': 0.72}

 90%|█████████ | 181/200 [01:00<00:05,  3.51it/s]
 91%|█████████ | 182/200 [01:00<00:05,  3.55it/s]
                                                 
{'loss': 0.7507, 'grad_norm': 4.923449261505112, 'learning_rate': 4.218267581201296e-08, 'epoch': 0.73}

 91%|█████████ | 182/200 [01:00<00:05,  3.55it/s]
 92%|█████████▏| 183/200 [01:00<00:04,  3.41it/s]
                                                 
{'loss': 1.2759, 'grad_norm': 9.24634046592049, 'learning_rate': 3.765473356596982e-08, 'epoch': 0.73}

 92%|█████████▏| 183/200 [01:00<00:04,  3.41it/s]
 92%|█████████▏| 184/200 [01:00<00:04,  3.44it/s]
                                                 
{'loss': 1.1042, 'grad_norm': 8.5820712547429, 'learning_rate': 3.3379149687388864e-08, 'epoch': 0.74}

 92%|█████████▏| 184/200 [01:00<00:04,  3.44it/s]
 92%|█████████▎| 185/200 [01:01<00:04,  3.48it/s]
                                                 
{'loss': 0.2885, 'grad_norm': 2.865648901453876, 'learning_rate': 2.9357045374040823e-08, 'epoch': 0.74}

 92%|█████████▎| 185/200 [01:01<00:04,  3.48it/s]
 93%|█████████▎| 186/200 [01:01<00:04,  3.43it/s]
                                                 
{'loss': 0.882, 'grad_norm': 5.72157926352496, 'learning_rate': 2.5589475353073985e-08, 'epoch': 0.74}

 93%|█████████▎| 186/200 [01:01<00:04,  3.43it/s]
 94%|█████████▎| 187/200 [01:01<00:03,  3.46it/s]
                                                 
{'loss': 0.8762, 'grad_norm': 6.245811890235959, 'learning_rate': 2.2077427604429433e-08, 'epoch': 0.75}

 94%|█████████▎| 187/200 [01:01<00:03,  3.46it/s]
 94%|█████████▍| 188/200 [01:02<00:03,  3.48it/s]
                                                 
{'loss': 1.2159, 'grad_norm': 8.049528821341376, 'learning_rate': 1.8821823101760948e-08, 'epoch': 0.75}

 94%|█████████▍| 188/200 [01:02<00:03,  3.48it/s]
 94%|█████████▍| 189/200 [01:02<00:03,  3.42it/s]
                                                 
{'loss': 0.8972, 'grad_norm': 6.3149092203050206, 'learning_rate': 1.582351557092576e-08, 'epoch': 0.76}

 94%|█████████▍| 189/200 [01:02<00:03,  3.42it/s]
 95%|█████████▌| 190/200 [01:02<00:02,  3.46it/s]
                                                 
{'loss': 1.2298, 'grad_norm': 8.271634028678646, 'learning_rate': 1.3083291266109298e-08, 'epoch': 0.76}

 95%|█████████▌| 190/200 [01:02<00:02,  3.46it/s]
 96%|█████████▌| 191/200 [01:03<00:02,  3.34it/s]
                                                 
{'loss': 1.2073, 'grad_norm': 7.939533123443828, 'learning_rate': 1.0601868763643995e-08, 'epoch': 0.76}

 96%|█████████▌| 191/200 [01:03<00:02,  3.34it/s]
 96%|█████████▌| 192/200 [01:03<00:02,  3.39it/s]
                                                 
{'loss': 0.8603, 'grad_norm': 5.46555535875712, 'learning_rate': 8.379898773574923e-09, 'epoch': 0.77}

 96%|█████████▌| 192/200 [01:03<00:02,  3.39it/s]
 96%|█████████▋| 193/200 [01:03<00:02,  3.44it/s]
                                                 
{'loss': 0.9093, 'grad_norm': 5.097026496661168, 'learning_rate': 6.417963969022389e-09, 'epoch': 0.77}

 96%|█████████▋| 193/200 [01:03<00:02,  3.44it/s]
 97%|█████████▋| 194/200 [01:03<00:01,  3.12it/s]
                                                 
{'loss': 0.8745, 'grad_norm': 5.340546300139673, 'learning_rate': 4.716578833386053e-09, 'epoch': 0.78}

 97%|█████████▋| 194/200 [01:03<00:01,  3.12it/s]
 98%|█████████▊| 195/200 [01:04<00:01,  3.25it/s]
                                                 
{'loss': 1.4355, 'grad_norm': 8.957256542222266, 'learning_rate': 3.276189525430628e-09, 'epoch': 0.78}

 98%|█████████▊| 195/200 [01:04<00:01,  3.25it/s]
 98%|█████████▊| 196/200 [01:04<00:01,  3.32it/s]
                                                 
{'loss': 1.0372, 'grad_norm': 5.853672355154831, 'learning_rate': 2.0971737622883512e-09, 'epoch': 0.78}

 98%|█████████▊| 196/200 [01:04<00:01,  3.32it/s]
 98%|█████████▊| 197/200 [01:04<00:00,  3.37it/s]
                                                 
{'loss': 0.9433, 'grad_norm': 6.846677110633697, 'learning_rate': 1.1798407204093308e-09, 'epoch': 0.79}

 98%|█████████▊| 197/200 [01:04<00:00,  3.37it/s]
 99%|█████████▉| 198/200 [01:05<00:00,  3.45it/s]
                                                 
{'loss': 1.1101, 'grad_norm': 8.386110593780247, 'learning_rate': 5.244309544850667e-10, 'epoch': 0.79}

 99%|█████████▉| 198/200 [01:05<00:00,  3.45it/s]
100%|█████████▉| 199/200 [01:05<00:00,  3.54it/s]
                                                 
{'loss': 1.2677, 'grad_norm': 9.903234365767595, 'learning_rate': 1.311163343677979e-10, 'epoch': 0.8}

100%|█████████▉| 199/200 [01:05<00:00,  3.54it/s]
100%|██████████| 200/200 [01:05<00:00,  3.57it/s]
                                                 
{'loss': 0.9578, 'grad_norm': 6.0631958866881055, 'learning_rate': 0.0, 'epoch': 0.8}

100%|██████████| 200/200 [01:05<00:00,  3.57it/s]/work/.env/openmind_finetune/lib/python3.10/site-packages/peft/utils/save_and_load.py:257: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.
  warnings.warn(
/work/.env/openmind_finetune/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/work/.env/openmind_finetune/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/work/.env/openmind_finetune/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/work/.env/openmind_finetune/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/work/.env/openmind_finetune/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/work/.env/openmind_finetune/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/work/.env/openmind_finetune/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(
/work/.env/openmind_finetune/lib/python3.10/site-packages/torch/nn/modules/module.py:1879: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.
  warnings.warn(


{'train_runtime': 99.4398, 'train_samples_per_second': 32.18, 'train_steps_per_second': 2.011, 'train_loss': 1.3380357602238655, 'epoch': 0.8}

100%|██████████| 200/200 [01:32<00:00,  3.57it/s]
100%|██████████| 200/200 [01:32<00:00,  2.15it/s]
/work/.env/openmind_finetune/lib/python3.10/site-packages/peft/utils/save_and_load.py:257: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.
  warnings.warn(
/work/.env/openmind_finetune/lib/python3.10/site-packages/peft/utils/save_and_load.py:257: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.
  warnings.warn(
/work/.env/openmind_finetune/lib/python3.10/site-packages/peft/utils/save_and_load.py:257: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.
  warnings.warn(
/work/.env/openmind_finetune/lib/python3.10/site-packages/peft/utils/save_and_load.py:257: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.
  warnings.warn(
/work/.env/openmind_finetune/lib/python3.10/site-packages/peft/utils/save_and_load.py:257: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.
  warnings.warn(
/work/.env/openmind_finetune/lib/python3.10/site-packages/peft/utils/save_and_load.py:257: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.
  warnings.warn(
/work/.env/openmind_finetune/lib/python3.10/site-packages/peft/utils/save_and_load.py:257: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.
  warnings.warn(
